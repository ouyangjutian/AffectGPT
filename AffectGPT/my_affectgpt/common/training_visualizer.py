"""
è®­ç»ƒå¯è§†åŒ–å·¥å…· - è‡ªåŠ¨ä¿å­˜å­¦ä¹ ç‡å’ŒLossæ›²çº¿å›¾
é›†æˆåˆ°è®­ç»ƒæµç¨‹ä¸­ï¼Œæ— éœ€é¢å¤–å¯åŠ¨ç›‘æ§è„šæœ¬
"""

import os
import matplotlib
matplotlib.use('Agg')  # éGUIåç«¯
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path


class TrainingVisualizer:
    """è®­ç»ƒå¯è§†åŒ–å™¨ - è®°å½•å¹¶ç»˜åˆ¶å­¦ä¹ ç‡å’ŒLossæ›²çº¿"""
    
    def __init__(self, output_dir, enabled=True):
        """
        Args:
            output_dir (str): è¾“å‡ºç›®å½•
            enabled (bool): æ˜¯å¦å¯ç”¨å¯è§†åŒ–
        """
        self.enabled = enabled
        if not self.enabled:
            return
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.steps = []
        self.lrs = []
        self.losses = []
        self.epochs = []
        
        print(f"ğŸ“Š Training Visualizer enabled: {self.output_dir}")
    
    def add_scalar(self, epoch, step, lr, loss):
        """
        æ·»åŠ ä¸€æ¡è®­ç»ƒè®°å½•
        
        Args:
            epoch (int): å½“å‰epoch
            step (int): å½“å‰stepï¼ˆepochå†…çš„æ­¥æ•°ï¼‰
            lr (float): å­¦ä¹ ç‡
            loss (float): æŸå¤±å€¼
        """
        if not self.enabled:
            return
        
        self.epochs.append(epoch)
        self.steps.append(len(self.steps))  # å…¨å±€æ­¥æ•°
        self.lrs.append(lr)
        self.losses.append(loss)
    
    def plot_and_save(self, suffix=''):
        """
        ç»˜åˆ¶å¹¶ä¿å­˜æ›²çº¿å›¾
        
        Args:
            suffix (str): æ–‡ä»¶ååç¼€ï¼ˆå¦‚'_epoch10'ï¼‰
        """
        if not self.enabled or len(self.steps) == 0:
            return
        
        # è®¾ç½®æ ·å¼
        plt.style.use('seaborn-v0_8-darkgrid')
        
        # åˆ›å»º2x2å­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'Training Progress - {len(self.steps)} steps recorded', 
                     fontsize=16, fontweight='bold')
        
        # 1. å­¦ä¹ ç‡æ›²çº¿ï¼ˆçº¿æ€§ï¼‰
        ax1 = axes[0, 0]
        ax1.plot(self.steps, self.lrs, linewidth=1.5, alpha=0.9, color='#3498db')
        ax1.set_xlabel('Steps', fontsize=12)
        ax1.set_ylabel('Learning Rate', fontsize=12)
        ax1.set_title('Learning Rate vs Steps (Linear Scale)', fontsize=13, fontweight='bold')
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.ticklabel_format(axis='x', style='plain')
        
        # æ·»åŠ warmupå’Œè¡°å‡é˜¶æ®µæ ‡æ³¨
        if len(self.lrs) > 10:
            max_lr_idx = np.argmax(self.lrs)
            ax1.axvline(x=self.steps[max_lr_idx], color='red', linestyle='--', 
                       alpha=0.5, label=f'Peak LR (step {self.steps[max_lr_idx]})')
            ax1.legend(fontsize=10)
        
        # 2. å­¦ä¹ ç‡æ›²çº¿ï¼ˆå¯¹æ•°ï¼‰
        ax2 = axes[0, 1]
        ax2.plot(self.steps, self.lrs, linewidth=1.5, alpha=0.9, color='#e67e22')
        ax2.set_xlabel('Steps', fontsize=12)
        ax2.set_ylabel('Learning Rate (log scale)', fontsize=12)
        ax2.set_title('Learning Rate vs Steps (Log Scale)', fontsize=13, fontweight='bold')
        ax2.set_yscale('log')
        ax2.grid(True, alpha=0.3, linestyle='--')
        ax2.ticklabel_format(axis='x', style='plain')
        
        # 3. Lossæ›²çº¿
        ax3 = axes[1, 0]
        # åŸå§‹lossï¼ˆåŠé€æ˜ï¼‰
        ax3.plot(self.steps, self.losses, linewidth=0.5, alpha=0.3, color='gray', label='Raw Loss')
        
        # å¹³æ»‘loss
        if len(self.losses) > 50:
            window = min(100, len(self.losses) // 10)
            if window > 1:
                smoothed_loss = np.convolve(self.losses, np.ones(window)/window, mode='valid')
                smoothed_steps = self.steps[window-1:]
                ax3.plot(smoothed_steps, smoothed_loss, linewidth=2.5, color='#e74c3c', 
                        label=f'Smoothed (window={window})')
        
        ax3.set_xlabel('Steps', fontsize=12)
        ax3.set_ylabel('Loss', fontsize=12)
        ax3.set_title('Loss vs Steps', fontsize=13, fontweight='bold')
        ax3.grid(True, alpha=0.3, linestyle='--')
        ax3.legend(fontsize=10)
        ax3.ticklabel_format(axis='x', style='plain')
        
        # æ·»åŠ æœ€ä½lossæ ‡æ³¨
        min_loss_idx = np.argmin(self.losses)
        ax3.plot(self.steps[min_loss_idx], self.losses[min_loss_idx], 'r*', 
                markersize=15, label=f'Min Loss: {self.losses[min_loss_idx]:.4f}')
        ax3.legend(fontsize=10)
        
        # 4. æ¯ä¸ªEpochçš„å¹³å‡Loss
        ax4 = axes[1, 1]
        if len(self.epochs) > 0:
            unique_epochs = sorted(set(self.epochs))
            epoch_losses = []
            epoch_stds = []
            
            for ep in unique_epochs:
                epoch_mask = [i for i, e in enumerate(self.epochs) if e == ep]
                losses_in_epoch = [self.losses[i] for i in epoch_mask]
                avg_loss = np.mean(losses_in_epoch)
                std_loss = np.std(losses_in_epoch)
                epoch_losses.append(avg_loss)
                epoch_stds.append(std_loss)
            
            # ç»˜åˆ¶å¹³å‡loss
            ax4.plot(unique_epochs, epoch_losses, marker='o', linewidth=2.5, 
                    markersize=8, color='#9b59b6', label='Average Loss')
            
            # æ·»åŠ æ ‡å‡†å·®é˜´å½±
            if len(epoch_losses) > 1:
                ax4.fill_between(unique_epochs, 
                                np.array(epoch_losses) - np.array(epoch_stds),
                                np.array(epoch_losses) + np.array(epoch_stds),
                                alpha=0.2, color='#9b59b6')
            
            ax4.set_xlabel('Epoch', fontsize=12)
            ax4.set_ylabel('Average Loss', fontsize=12)
            ax4.set_title('Average Loss per Epoch', fontsize=13, fontweight='bold')
            ax4.grid(True, alpha=0.3, linestyle='--')
            ax4.legend(fontsize=10)
            
            # è®¾ç½®æ•´æ•°åˆ»åº¦
            if len(unique_epochs) < 20:
                ax4.set_xticks(unique_epochs)
        
        plt.tight_layout()
        
        # ä¿å­˜æ ‡å‡†åˆ†è¾¨ç‡
        output_path = self.output_dir / f'training_curves{suffix}.png'
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Training curves saved: {output_path}")
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬ï¼ˆæ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡ï¼Œé¿å…æ–‡ä»¶è¿‡å¤šï¼‰
        if suffix == '' or 'final' in suffix.lower() or (self.epochs and self.epochs[-1] % 5 == 0):
            output_path_hd = self.output_dir / f'training_curves_hd{suffix}.png'
            
            fig, axes = plt.subplots(2, 2, figsize=(20, 15))
            fig.suptitle(f'Training Progress (High Resolution) - {len(self.steps)} steps', 
                        fontsize=20, fontweight='bold')
            
            # é‡æ–°ç»˜åˆ¶ï¼ˆé«˜åˆ†è¾¨ç‡ï¼‰
            # 1. å­¦ä¹ ç‡ï¼ˆçº¿æ€§ï¼‰
            ax1 = axes[0, 0]
            ax1.plot(self.steps, self.lrs, linewidth=2, alpha=0.9, color='#3498db')
            ax1.set_xlabel('Steps', fontsize=14)
            ax1.set_ylabel('Learning Rate', fontsize=14)
            ax1.set_title('Learning Rate vs Steps (Linear Scale)', fontsize=16, fontweight='bold')
            ax1.grid(True, alpha=0.3, linestyle='--')
            if len(self.lrs) > 10:
                max_lr_idx = np.argmax(self.lrs)
                ax1.axvline(x=self.steps[max_lr_idx], color='red', linestyle='--', 
                           alpha=0.5, label=f'Peak LR (step {self.steps[max_lr_idx]})')
                ax1.legend(fontsize=12)
            
            # 2. å­¦ä¹ ç‡ï¼ˆå¯¹æ•°ï¼‰
            ax2 = axes[0, 1]
            ax2.plot(self.steps, self.lrs, linewidth=2, alpha=0.9, color='#e67e22')
            ax2.set_xlabel('Steps', fontsize=14)
            ax2.set_ylabel('Learning Rate (log scale)', fontsize=14)
            ax2.set_title('Learning Rate vs Steps (Log Scale)', fontsize=16, fontweight='bold')
            ax2.set_yscale('log')
            ax2.grid(True, alpha=0.3, linestyle='--')
            
            # 3. Loss
            ax3 = axes[1, 0]
            ax3.plot(self.steps, self.losses, linewidth=0.8, alpha=0.3, color='gray', label='Raw Loss')
            if len(self.losses) > 50:
                window = min(100, len(self.losses) // 10)
                if window > 1:
                    smoothed_loss = np.convolve(self.losses, np.ones(window)/window, mode='valid')
                    smoothed_steps = self.steps[window-1:]
                    ax3.plot(smoothed_steps, smoothed_loss, linewidth=3, color='#e74c3c', 
                            label=f'Smoothed (window={window})')
            ax3.set_xlabel('Steps', fontsize=14)
            ax3.set_ylabel('Loss', fontsize=14)
            ax3.set_title('Loss vs Steps', fontsize=16, fontweight='bold')
            ax3.grid(True, alpha=0.3, linestyle='--')
            min_loss_idx = np.argmin(self.losses)
            ax3.plot(self.steps[min_loss_idx], self.losses[min_loss_idx], 'r*', 
                    markersize=20, label=f'Min Loss: {self.losses[min_loss_idx]:.4f}')
            ax3.legend(fontsize=12)
            
            # 4. Epoch Loss
            ax4 = axes[1, 1]
            if len(self.epochs) > 0:
                unique_epochs = sorted(set(self.epochs))
                epoch_losses = []
                epoch_stds = []
                for ep in unique_epochs:
                    epoch_mask = [i for i, e in enumerate(self.epochs) if e == ep]
                    losses_in_epoch = [self.losses[i] for i in epoch_mask]
                    epoch_losses.append(np.mean(losses_in_epoch))
                    epoch_stds.append(np.std(losses_in_epoch))
                
                ax4.plot(unique_epochs, epoch_losses, marker='o', linewidth=3, 
                        markersize=10, color='#9b59b6', label='Average Loss')
                if len(epoch_losses) > 1:
                    ax4.fill_between(unique_epochs, 
                                    np.array(epoch_losses) - np.array(epoch_stds),
                                    np.array(epoch_losses) + np.array(epoch_stds),
                                    alpha=0.2, color='#9b59b6')
                ax4.set_xlabel('Epoch', fontsize=14)
                ax4.set_ylabel('Average Loss', fontsize=14)
                ax4.set_title('Average Loss per Epoch', fontsize=16, fontweight='bold')
                ax4.grid(True, alpha=0.3, linestyle='--')
                ax4.legend(fontsize=12)
                if len(unique_epochs) < 20:
                    ax4.set_xticks(unique_epochs)
            
            plt.tight_layout()
            plt.savefig(output_path_hd, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… High-res curves saved: {output_path_hd}")
    
    def print_statistics(self):
        """æ‰“å°è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        if not self.enabled or len(self.steps) == 0:
            return
        
        print("\n" + "="*70)
        print("ğŸ“Š Training Statistics")
        print("="*70)
        print(f"  Total Steps:          {len(self.steps):,}")
        print(f"  Current Epoch:        {self.epochs[-1]}")
        print(f"  Current Learning Rate: {self.lrs[-1]:.2e}")
        print(f"  Latest Loss:          {self.losses[-1]:.6f}")
        
        if len(self.losses) > 100:
            recent_loss = np.mean(self.losses[-100:])
            print(f"  Recent 100 Avg Loss:  {recent_loss:.6f}")
        
        min_loss = min(self.losses)
        min_loss_step = self.steps[self.losses.index(min_loss)]
        print(f"  Best Loss:            {min_loss:.6f} (Step {min_loss_step})")
        print(f"  Max Learning Rate:    {max(self.lrs):.2e}")
        print(f"  Min Learning Rate:    {min(self.lrs):.2e}")
        print("="*70 + "\n")
    
    def save_data(self, suffix=''):
        """ä¿å­˜åŸå§‹æ•°æ®ä¸ºnumpyæ–‡ä»¶"""
        if not self.enabled or len(self.steps) == 0:
            return
        
        data_file = self.output_dir / f'training_data{suffix}.npz'
        np.savez(data_file,
                 steps=np.array(self.steps),
                 epochs=np.array(self.epochs),
                 lrs=np.array(self.lrs),
                 losses=np.array(self.losses))
        print(f"ğŸ’¾ Training data saved: {data_file}")
    
    def load_data(self, data_file):
        """åŠ è½½ä¹‹å‰ä¿å­˜çš„æ•°æ®ï¼ˆç”¨äºæ¢å¤è®­ç»ƒï¼‰"""
        if not self.enabled:
            return
        
        data_file = Path(data_file)
        if not data_file.exists():
            print(f"âš ï¸  Data file not found: {data_file}")
            return
        
        data = np.load(data_file)
        self.steps = data['steps'].tolist()
        self.epochs = data['epochs'].tolist()
        self.lrs = data['lrs'].tolist()
        self.losses = data['losses'].tolist()
        
        print(f"âœ… Loaded {len(self.steps)} training records from {data_file}")
