#!/usr/bin/env python3
"""
ä½¿ç”¨CLIPå¯¹MER-Factoryè¾“å‡ºçš„fine_grained_descriptionsè¿›è¡Œç¼–ç 
"""
import os
import json
import clip
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
from rich.console import Console
from rich.progress import Progress, TaskID, BarColumn, TextColumn, MofNCompleteColumn

console = Console()

def load_clip_model(device: str = "cuda" if torch.cuda.is_available() else "cpu"):
    """åŠ è½½CLIPæ¨¡å‹"""
    console.print(f"ğŸ”§ Loading CLIP model on device: [yellow]{device}[/yellow]")
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, device

def find_au_analysis_files(output_dir: str) -> List[Tuple[str, str]]:
    """æŸ¥æ‰¾æ‰€æœ‰çš„au_analysis.jsonæ–‡ä»¶"""
    output_path = Path(output_dir)
    if not output_path.exists():
        console.print(f"âŒ Output directory not found: {output_dir}")
        return []
    
    files_found = []
    for subfolder in output_path.iterdir():
        if subfolder.is_dir():
            # æŸ¥æ‰¾*_au_analysis.jsonæ–‡ä»¶
            for json_file in subfolder.glob("*_au_analysis.json"):
                files_found.append((subfolder.name, str(json_file)))
                
    console.print(f"ğŸ“ Found {len(files_found)} AU analysis files")
    return files_found

def extract_fine_grained_descriptions(json_file_path: str) -> Dict[str, str]:
    """ä»AUåˆ†æJSONæ–‡ä»¶ä¸­æå–fine_grained_descriptions"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        fine_grained_descriptions = data.get('fine_grained_descriptions', {})
        return fine_grained_descriptions
    
    except Exception as e:
        console.print(f"âŒ Error reading {json_file_path}: {e}")
        return {}

def encode_descriptions_with_clip(
    descriptions: Dict[str, str], 
    model, 
    device: str
) -> Dict[str, np.ndarray]:
    """ä½¿ç”¨CLIPç¼–ç æè¿°æ–‡æœ¬"""
    encoded_features = {}
    
    if not descriptions:
        return encoded_features
    
    # æ‰¹é‡å¤„ç†æ‰€æœ‰æè¿°
    frame_indices = list(descriptions.keys())
    texts = list(descriptions.values())
    
    # ä½¿ç”¨CLIPçš„æ–‡æœ¬ç¼–ç å™¨
    text_tokens = clip.tokenize(texts).to(device)
    
    with torch.no_grad():
        text_features = model.encode_text(text_tokens)
        # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        text_features = text_features.cpu().numpy()
    
    # å°†ç¼–ç ç»“æœæ˜ å°„å›frame index
    for i, frame_idx in enumerate(frame_indices):
        encoded_features[frame_idx] = text_features[i]
    
    return encoded_features

def save_encoded_features(
    encoded_features: Dict[str, np.ndarray], 
    video_id: str, 
    output_file: str
):
    """ä¿å­˜ç¼–ç åçš„ç‰¹å¾"""
    # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
    serializable_features = {}
    for frame_idx, features in encoded_features.items():
        serializable_features[frame_idx] = {
            'features': features.tolist(),
            'shape': features.shape,
            'dtype': str(features.dtype)
        }
    
    save_data = {
        'video_id': video_id,
        'clip_model': 'ViT-B/32',
        'feature_dim': 512,  # ViT-B/32çš„ç‰¹å¾ç»´åº¦
        'encoded_fine_grained_descriptions': serializable_features
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, indent=2, ensure_ascii=False)
    
    console.print(f"ğŸ’¾ Saved encoded features to: [green]{output_file}[/green]")

def process_all_files(mer_factory_output_dir: str, affectgpt_output_dir: str):
    """å¤„ç†æ‰€æœ‰AUåˆ†ææ–‡ä»¶"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(affectgpt_output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½CLIPæ¨¡å‹
    model, device = load_clip_model()
    
    # æŸ¥æ‰¾æ‰€æœ‰AUåˆ†ææ–‡ä»¶
    au_files = find_au_analysis_files(mer_factory_output_dir)
    
    if not au_files:
        console.print("âŒ No AU analysis files found!")
        return
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        MofNCompleteColumn(),
        refresh_per_second=2,
    ) as progress:
        
        task = progress.add_task("ğŸ”„ Processing AU analysis files", total=len(au_files))
        
        for video_id, json_file_path in au_files:
            progress.update(task, description=f"Processing {video_id}")
            
            # æå–fine_grained_descriptions
            descriptions = extract_fine_grained_descriptions(json_file_path)
            
            if descriptions:
                # ä½¿ç”¨CLIPç¼–ç 
                encoded_features = encode_descriptions_with_clip(descriptions, model, device)
                
                # ä¿å­˜ç¼–ç ç»“æœ
                output_file = output_path / f"{video_id}_clip_features.json"
                save_encoded_features(encoded_features, video_id, str(output_file))
                
                console.print(f"âœ… Processed {video_id}: {len(descriptions)} descriptions encoded")
            else:
                console.print(f"âš ï¸  No fine_grained_descriptions found in {video_id}")
            
            progress.advance(task)
        
        progress.update(task, description="âœ… All files processed")

def main():
    """ä¸»å‡½æ•°"""
    console.rule("[bold blue]ğŸ¯ CLIP Encoding for Fine-Grained Descriptions[/bold blue]")
    
    # é…ç½®è·¯å¾„
    mer_factory_output = "G:/Project/MER-Factory/output"
    affectgpt_output = "G:/Project/AffectGPT/AffectGPT/clip_encoded_features"
    
    console.print(f"ğŸ“‚ Input directory: [cyan]{mer_factory_output}[/cyan]")
    console.print(f"ğŸ“‚ Output directory: [cyan]{affectgpt_output}[/cyan]")
    
    # æ£€æŸ¥CLIPæ˜¯å¦å¯ç”¨
    try:
        import clip
        console.print("âœ… CLIP module imported successfully")
    except ImportError:
        console.print("âŒ CLIP not installed. Please run: pip install git+https://github.com/openai/CLIP.git")
        return
    
    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    process_all_files(mer_factory_output, affectgpt_output)
    
    console.rule("[bold green]âœ¨ Encoding Complete![/bold green]")

if __name__ == "__main__":
    main()
