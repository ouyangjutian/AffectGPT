# AffectGPT Pre-Fusion å†…éƒ¨æœºåˆ¶è¯¦è§£

> **Cross-Attention (Q-Former) è¯¦ç»†æ¶æ„å›¾**  
> æ¸…æ™°æ ‡æ³¨ Query (Q)ã€Key (K)ã€Value (V) çš„æ¥æºä¸è®¡ç®—æµç¨‹

---

## ğŸ“Š æ•´ä½“æ¶æ„å›¾

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Fused Tokens (E^f')           â”‚
                    â”‚   [batch, num_queries, llm_dim] â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Linear Projector            â”‚
                    â”‚   multi_llama_proj            â”‚
                    â”‚   768 â†’ llm_dim (e.g. 4096)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Q-Former Output             â”‚
                    â”‚   [batch, num_queries, 768]   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘         Cross-Attention (Pre-Fusion)              â•‘
        â•‘              Q-Former (BERT-based)                â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘                                                   â•‘
        â•‘  Q (Query)          K, V (Key, Value)            â•‘
        â•‘      â†“                      â†“                     â•‘
        â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â•‘
        â•‘  â”‚ Zq     â”‚          â”‚ Concat(Za,Zf)â”‚             â•‘
        â•‘  â”‚        â”‚          â”‚   + PosEmb   â”‚             â•‘
        â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â•‘
        â•‘      â”‚                      â”‚                     â•‘
        â•‘      â”‚                      â”‚                     â•‘
        â•‘      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â•‘
        â•‘                 â”‚                                 â•‘
        â•‘          Cross-Attention                          â•‘
        â•‘    Attention(Q, K, V) = softmax(QK^T/âˆšd)V        â•‘
        â•‘                                                   â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        â–²               â–²
                        â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                              â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Q    â”‚                                    â”‚  K, V   â”‚
   â”‚ (Query)â”‚                                    â”‚(Key,Val)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                              â”‚
        â”‚                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Learnable     â”‚                          â”‚  Concat & PosEmb  â”‚
â”‚ Query Tokens  â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  (Zq)         â”‚                                    â”‚
â”‚               â”‚                                    â”‚
â”‚ [num_queries, â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     768]      â”‚                     â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   Za (Audio) â”‚            â”‚  Zf (Face)   â”‚
                               â”‚              â”‚            â”‚              â”‚
                               â”‚ [batch, ta,  â”‚            â”‚ [batch, tf,  â”‚
                               â”‚  audio_dim]  â”‚            â”‚  video_dim]  â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” è¯¦ç»†è®¡ç®—æµç¨‹

### Step 1: è¾“å…¥æ¨¡æ€ç‰¹å¾

```python
# è¾“å…¥
Za (Audio): [batch, ta, audio_dim]     # ta = éŸ³é¢‘æ—¶é—´æ­¥æ•°ï¼ˆå¦‚8ï¼‰
Zf (Face):  [batch, tf, video_dim]     # tf = è§†é¢‘æ—¶é—´æ­¥æ•°ï¼ˆå¦‚32ï¼‰
```

**ä»£ç ä½ç½®**: `affectgpt.py` Line 848-849

### Step 2: ç‰¹å¾å¯¹é½ï¼ˆæŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦ï¼‰

```python
# ä½¿ç”¨çº¿æ€§å±‚å°†ä¸åŒç»´åº¦çš„ç‰¹å¾æŠ•å½±åˆ°max_hidden_size
Za' = multi_audio_embs(Za)  # [batch, ta, max_hidden_size]
Zf' = multi_video_embs(Zf)  # [batch, tf, max_hidden_size]
```

**ä½œç”¨**: å°†Audioå’ŒFaceç‰¹å¾æŠ•å½±åˆ°ç›¸åŒç»´åº¦ç©ºé—´ï¼ˆå¦‚1024ç»´ï¼‰

**ä»£ç ä½ç½®**: `affectgpt.py` Line 850-851

### Step 3: ç‰¹å¾æ‹¼æ¥ï¼ˆæ„é€ K, Vçš„åŸºç¡€ï¼‰

```python
# æ—¶é—´ç»´åº¦æ‹¼æ¥
Z_concat = Concat([Za', Zf'], dim=1)  # [batch, ta+tf, max_hidden_size]
```

**ç¤ºä¾‹**: å¦‚æœ ta=8, tf=32ï¼Œåˆ™ Z_concat çš„æ—¶é—´ç»´åº¦ä¸º 40

**ä»£ç ä½ç½®**: `affectgpt.py` Line 852

### Step 4: æ·»åŠ ä½ç½®ç¼–ç 

```python
# ç”Ÿæˆä½ç½®ID
position_ids = [0, 1, 2, ..., ta+tf-1]  # [batch, ta+tf]

# æŸ¥è¡¨è·å–ä½ç½®ç¼–ç 
pos_emb = multi_position_embedding(position_ids)  # [batch, ta+tf, max_hidden_size]

# åŠ åˆ°ç‰¹å¾ä¸Š
Z_kv = Z_concat + pos_emb  # [batch, ta+tf, max_hidden_size]
```

**ä½œç”¨**: ä¸ºæ¨¡å‹æä¾›åºåˆ—ä½ç½®ä¿¡æ¯

**ä»£ç ä½ç½®**: `affectgpt.py` Line 857-860

### Step 5: å‡†å¤‡Queryï¼ˆå¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡ï¼‰

```python
# multi_query_tokens æ˜¯å¯å­¦ä¹ å‚æ•°
# åˆå§‹åŒ–æ—¶éšæœºåˆå§‹åŒ–ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°
Zq = multi_query_tokens  # [num_multi_query_token, 768]

# Expandåˆ°batchç»´åº¦
Zq_batch = Zq.expand(batch, -1, -1)  # [batch, num_multi_query_token, 768]
```

**ç‰¹ç‚¹**: 
- **å¯å­¦ä¹ **: éšç€è®­ç»ƒä¸æ–­ä¼˜åŒ–
- **æ•°é‡å›ºå®š**: num_multi_query_tokenï¼ˆå¦‚16ä¸ªï¼‰
- **ç»´åº¦å›ºå®š**: 768ï¼ˆBERT hidden sizeï¼‰

**ä»£ç ä½ç½®**: `affectgpt.py` Line 864

### Step 6: Cross-Attentionè®¡ç®—

```python
# Q-FormeråŸºäºBERTå®ç°
# å†…éƒ¨ä½¿ç”¨æ ‡å‡†çš„Cross-Attentionæœºåˆ¶

query_output = multi_Qformer.bert(
    query_embeds=Zq_batch,           # Q: [batch, num_queries, 768]
    encoder_hidden_states=Z_kv,      # K, V: [batch, ta+tf, max_hidden_size]
    encoder_attention_mask=frame_atts,  # Attention mask
    return_dict=True,
)
```

**Cross-Attentionè®¡ç®—**:
```
Q = Zq_batch                         # [batch, num_queries, 768]
K = Linear_K(Z_kv)                   # [batch, ta+tf, 768]
V = Linear_V(Z_kv)                   # [batch, ta+tf, 768]

Attention_Scores = softmax(Q @ K^T / âˆšd_k)  # [batch, num_queries, ta+tf]
Output = Attention_Scores @ V              # [batch, num_queries, 768]
```

**ä»£ç ä½ç½®**: `affectgpt.py` Line 865-870

### Step 7: æå–è¾“å‡º

```python
multi_hidden = query_output.last_hidden_state  # [batch, num_queries, 768]
```

**ä»£ç ä½ç½®**: `affectgpt.py` Line 871

### Step 8: æŠ•å½±åˆ°LLMç©ºé—´

```python
inputs_llama = multi_llama_proj(multi_hidden)  # [batch, num_queries, llm_dim]
# ä¾‹å¦‚: llm_dim = 4096 (for LLaMA-7B)
```

**ä½œç”¨**: å°†Q-Formerè¾“å‡ºæŠ•å½±åˆ°LLMçš„embeddingç»´åº¦

**ä»£ç ä½ç½®**: `affectgpt.py` Line 874

---

## ğŸ¯ Q, K, V è¯¦ç»†è¯´æ˜

### Query (Q)

| å±æ€§ | å€¼ |
|------|-----|
| **æ¥æº** | `self.multi_query_tokens`ï¼ˆå¯å­¦ä¹ å‚æ•°ï¼‰ |
| **ç»´åº¦** | `[num_multi_query_token, 768]` |
| **ç‰¹æ€§** | å›ºå®šæ•°é‡ï¼Œè®­ç»ƒä¸­å­¦ä¹ åˆ°å¦‚ä½•queryæœ‰ç”¨çš„è·¨æ¨¡æ€ä¿¡æ¯ |
| **åˆå§‹åŒ–** | éšæœºåˆå§‹åŒ–ï¼ˆ`nn.Parameter`ï¼‰ |
| **æ˜¯å¦å¯å­¦ä¹ ** | âœ… æ˜¯ï¼ˆé™¤éfrozenï¼‰ |

**ä»£ç å®šä¹‰**:
```python
self.multi_query_tokens = nn.Parameter(
    torch.zeros(1, num_multi_query_token, 768)
)
```

### Key & Value (K, V)

| å±æ€§ | å€¼ |
|------|-----|
| **æ¥æº** | Audioç‰¹å¾ + Faceç‰¹å¾ï¼ˆconcatåï¼‰ |
| **ç»´åº¦** | `[batch, ta+tf, max_hidden_size]` |
| **ç‰¹æ€§** | åŒ…å«å®Œæ•´çš„éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯ |
| **ä½ç½®ç¼–ç ** | âœ… æ·»åŠ äº†position embedding |
| **æ˜¯å¦å¯å­¦ä¹ ** | âŒ ç‰¹å¾æœ¬èº«ä¸å­¦ä¹ ï¼Œä½†æŠ•å½±å±‚å’Œpos_embå¯å­¦ä¹  |

**å¤„ç†æµç¨‹**:
```
Audio [batch, ta, audio_dim] 
  â†’ Linear â†’ [batch, ta, max_hidden_size]
  
Face [batch, tf, video_dim]
  â†’ Linear â†’ [batch, tf, max_hidden_size]
  
Concat â†’ [batch, ta+tf, max_hidden_size]
  + PosEmb â†’ [batch, ta+tf, max_hidden_size]
  
  â†’ ä½œä¸º K, V è¾“å…¥åˆ°Cross-Attention
```

---

## ğŸ“ ç»´åº¦å˜åŒ–å…¨æµç¨‹

```
è¾“å…¥:
  Za: [3, 8, 1024]        # batch=3, audio_frames=8, audio_dim=1024
  Zf: [3, 32, 1024]       # batch=3, face_frames=32, face_dim=1024

å¯¹é½:
  Za': [3, 8, 1024]       # é€šè¿‡multi_audio_embs
  Zf': [3, 32, 1024]      # é€šè¿‡multi_video_embs

æ‹¼æ¥:
  Z_concat: [3, 40, 1024] # 8 + 32 = 40

ä½ç½®ç¼–ç :
  pos_emb: [3, 40, 1024]
  Z_kv: [3, 40, 1024]     # Z_concat + pos_emb

Queryå‡†å¤‡:
  Zq: [3, 16, 768]        # num_multi_query_token=16

Cross-Attention:
  Q: [3, 16, 768]         # from Zq
  K: [3, 40, 768]         # from Z_kvç»è¿‡Linear_K
  V: [3, 40, 768]         # from Z_kvç»è¿‡Linear_V
  
  Attention_Scores: [3, 16, 40]  # Q @ K^T
  Output: [3, 16, 768]           # Scores @ V

æŠ•å½±:
  inputs_llama: [3, 16, 4096]    # æŠ•å½±åˆ°LLMç©ºé—´
```

---

## ğŸ§  Cross-Attentionæœºåˆ¶è¯¦è§£

### æ ‡å‡†Cross-Attentionå…¬å¼

```
Attention(Q, K, V) = softmax(QÂ·K^T / âˆšd_k) Â· V
```

**å‚æ•°è¯´æ˜**:
- **Q (Query)**: `[batch, num_queries, d_model]` - "æˆ‘æƒ³è¦ä»€ä¹ˆä¿¡æ¯"
- **K (Key)**: `[batch, seq_len, d_model]` - "è¿™é‡Œæœ‰ä»€ä¹ˆä¿¡æ¯"
- **V (Value)**: `[batch, seq_len, d_model]` - "å…·ä½“çš„ä¿¡æ¯å†…å®¹"
- **d_k**: Keyçš„ç»´åº¦ï¼Œç”¨äºç¼©æ”¾ï¼ˆé˜²æ­¢softmaxé¥±å’Œï¼‰

### åœ¨Pre-Fusionä¸­çš„å®ä¾‹

```python
# å‡è®¾ num_queries=16, ta+tf=40, d_model=768

Q = Zq                    # [batch, 16, 768]
K = Linear_K(Z_kv)        # [batch, 40, 768]
V = Linear_V(Z_kv)        # [batch, 40, 768]

# Step 1: è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
scores = Q @ K^T / âˆš768   # [batch, 16, 40]
# æ¯ä¸ªqueryå¯¹40ä¸ªæ—¶é—´æ­¥çš„å…³æ³¨åº¦

# Step 2: Softmaxå½’ä¸€åŒ–
attn_weights = softmax(scores, dim=-1)  # [batch, 16, 40]
# æ¯è¡Œå’Œä¸º1ï¼Œè¡¨ç¤ºæ¦‚ç‡åˆ†å¸ƒ

# Step 3: åŠ æƒæ±‚å’ŒValue
output = attn_weights @ V  # [batch, 16, 768]
# 16ä¸ªqueryå„è‡ªèšåˆäº†40ä¸ªæ—¶é—´æ­¥çš„ä¿¡æ¯
```

### ç›´è§‚ç†è§£

1. **Query (Q)**: 16ä¸ª"é—®é¢˜"ï¼Œæ¯ä¸ªé—®é¢˜åœ¨å¯»æ‰¾ç‰¹å®šçš„è·¨æ¨¡æ€ä¿¡æ¯
   - ä¾‹å¦‚: "éŸ³é¢‘å’Œé¢éƒ¨è¡¨æƒ…æ˜¯å¦ä¸€è‡´ï¼Ÿ"
   - ä¾‹å¦‚: "å½“å‰çš„ä¸»å¯¼æƒ…æ„Ÿæ˜¯ä»€ä¹ˆï¼Ÿ"

2. **Key (K)**: 40ä¸ªæ—¶é—´æ­¥çš„"ç´¢å¼•"ï¼Œè¡¨ç¤ºæ¯ä¸ªæ—¶é—´æ­¥åŒ…å«ä»€ä¹ˆä¿¡æ¯
   - å‰8ä¸ª: éŸ³é¢‘çš„8ä¸ªæ—¶é—´æ­¥
   - å32ä¸ª: é¢éƒ¨çš„32ä¸ªæ—¶é—´æ­¥

3. **Value (V)**: 40ä¸ªæ—¶é—´æ­¥çš„"å†…å®¹"ï¼ŒçœŸå®çš„ç‰¹å¾è¡¨ç¤º

4. **Attention**: Queryä¸KeyåŒ¹é…ï¼Œå†³å®šä»å“ªäº›æ—¶é—´æ­¥æå–ä¿¡æ¯
   - æ³¨æ„åŠ›é«˜çš„æ—¶é—´æ­¥ä¼šå¯¹è¾“å‡ºè´¡çŒ®æ›´å¤§

---

## ğŸ’¡ å…³é”®è®¾è®¡è¦ç‚¹

### 1. ä¸ºä»€ä¹ˆä½¿ç”¨Learnable Queriesï¼Ÿ

**ä¼˜åŠ¿**:
- âœ… **è‡ªé€‚åº”å­¦ä¹ **: è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ åˆ°æœ€ä¼˜çš„queryç­–ç•¥
- âœ… **å›ºå®šè¾“å‡ºç»´åº¦**: æ— è®ºè¾“å…¥å¤šé•¿ï¼Œè¾“å‡ºç»´åº¦å›ºå®šï¼ˆnum_queriesï¼‰
- âœ… **å‹ç¼©ä¿¡æ¯**: å°†é•¿åºåˆ—ï¼ˆ40æ­¥ï¼‰å‹ç¼©ä¸ºçŸ­åºåˆ—ï¼ˆ16ä¸ªtokenï¼‰
- âœ… **è·¨æ¨¡æ€èåˆ**: Queryå­¦ä¹ å¦‚ä½•æ•´åˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯

**å¯¹æ¯”Random Queries**:
- Random: æ¯æ¬¡éšæœºé‡‡æ ·ï¼Œä¸ç¨³å®š
- Learnable: ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä¸“é—¨ä¼˜åŒ–

### 2. ä¸ºä»€ä¹ˆConcat Audioå’ŒFaceï¼Ÿ

**ä¼˜åŠ¿**:
- âœ… **æ—¶åºå¯¹é½**: ä¿ç•™æ—¶é—´ç»´åº¦çš„ä¿¡æ¯
- âœ… **å®Œæ•´ä¿¡æ¯**: ä¸ä¸¢å¤±ä»»ä½•æ¨¡æ€çš„ç‰¹å¾
- âœ… **äº¤äº’å»ºæ¨¡**: Cross-Attentionå¯ä»¥å­¦ä¹ éŸ³è§†é¢‘ä¹‹é—´çš„äº¤äº’

**å¯¹æ¯”Mean Pooling**:
- Mean: ä¸¢å¤±æ—¶åºä¿¡æ¯
- Concat: ä¿ç•™å®Œæ•´æ—¶åº

### 3. ä¸ºä»€ä¹ˆä½¿ç”¨Q-Former (BERT-based)ï¼Ÿ

**ä¼˜åŠ¿**:
- âœ… **é¢„è®­ç»ƒçŸ¥è¯†**: BERTå·²ç»å­¦ä¹ äº†å¼ºå¤§çš„è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›
- âœ… **å¤šå±‚æ³¨æ„åŠ›**: 2å±‚Transformerï¼Œå»ºæ¨¡æ›´å¤æ‚çš„å…³ç³»
- âœ… **æˆç†Ÿæ¶æ„**: BERTæ¶æ„ç¨³å®šå¯é 

---

## ğŸ“Š å¯è§†åŒ–ç¤ºä¾‹

### Attentionæƒé‡å¯è§†åŒ–ï¼ˆå‡è®¾ï¼‰

```
Query 1: [å…³æ³¨æƒ…æ„Ÿå¼ºåº¦]
  Audioæ­¥éª¤:  [0.05, 0.08, 0.15, 0.20, 0.10, 0.05, 0.03, 0.02]  (æƒé‡)
  Faceæ­¥éª¤:   [0.01, 0.01, ..., 0.03, 0.05, 0.08, 0.10, 0.04]  (æƒé‡)
  â†’ ä¸»è¦å…³æ³¨ç¬¬4ä¸ªéŸ³é¢‘æ­¥å’Œåå‡ ä¸ªé¢éƒ¨å¸§

Query 2: [å…³æ³¨è¡¨æƒ…ç»†èŠ‚]
  Audioæ­¥éª¤:  [0.01, 0.01, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01]
  Faceæ­¥éª¤:   [0.12, 0.10, 0.09, ..., 0.08, 0.05, 0.04, 0.03]
  â†’ ä¸»è¦å…³æ³¨å‰å‡ ä¸ªé¢éƒ¨å¸§

...

Query 16: [å…³æ³¨å…¨å±€ä¸€è‡´æ€§]
  Audioæ­¥éª¤:  [0.13, 0.12, 0.11, 0.10, 0.09, 0.08, 0.06, 0.05]
  Faceæ­¥éª¤:   [0.04, 0.04, 0.03, ..., 0.03, 0.02, 0.02, 0.08]
  â†’ æ¯”è¾ƒå‡åŒ€åœ°å…³æ³¨æ‰€æœ‰æ­¥éª¤
```

---

## ğŸ”§ å‚æ•°é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `num_multi_query_token` | 16 | Queryæ•°é‡ |
| `max_hidden_size` | 1024 | K,Vç‰¹å¾ç»´åº¦ |
| `bert_hidden_size` | 768 | Qç»´åº¦ï¼ˆBERTæ ‡å‡†ï¼‰ |
| `num_hidden_layers` | 2 | Q-Formerå±‚æ•° |
| `position_embedding_size` | 264 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `frozen_multi_Qformer` | False/True | æ˜¯å¦å†»ç»“Q-Former |

**ä»£ç ä½ç½®**: `affectgpt.py` Line 316-341

---

## ğŸ“ æ€»ç»“

### Q, K, V ä¸€å¥è¯æ€»ç»“

- **Q (Query)**: 16ä¸ªå¯å­¦ä¹ çš„"é—®é¢˜"ï¼Œè¯¢é—®éœ€è¦ä»€ä¹ˆè·¨æ¨¡æ€ä¿¡æ¯
- **K (Key)**: 40ä¸ªæ—¶é—´æ­¥çš„"ç´¢å¼•"ï¼Œæ¥è‡ªAudio+Faceçš„concat
- **V (Value)**: 40ä¸ªæ—¶é—´æ­¥çš„"å†…å®¹"ï¼ŒçœŸå®çš„éŸ³è§†é¢‘ç‰¹å¾

### Pre-Fusionæ ¸å¿ƒæ€æƒ³

é€šè¿‡**Cross-Attention**æœºåˆ¶ï¼Œè®©**å›ºå®šæ•°é‡çš„å¯å­¦ä¹ Queries**ä»**å˜é•¿çš„å¤šæ¨¡æ€åºåˆ—**ä¸­ï¼Œ**è‡ªé€‚åº”åœ°æå–**æœ€ç›¸å…³çš„è·¨æ¨¡æ€ä¿¡æ¯ï¼Œå®ç°ï¼š
1. âœ… ç»´åº¦å‹ç¼©ï¼ˆ40 â†’ 16ï¼‰
2. âœ… è·¨æ¨¡æ€èåˆï¼ˆAudio + Faceï¼‰
3. âœ… è¯­ä¹‰å¯¹é½ï¼ˆæŠ•å½±åˆ°LLMç©ºé—´ï¼‰

---

## ğŸ“š ç›¸å…³ä»£ç æ–‡ä»¶

- **æ¨¡å‹å®šä¹‰**: `my_affectgpt/models/affectgpt.py`
  - Line 316-341: Multi Q-Formeråˆå§‹åŒ–
  - Line 843-876: `encode_multi_qformer`å‡½æ•°
  
- **é…ç½®æ–‡ä»¶**: è®­ç»ƒé…ç½®ä¸­çš„fusionç›¸å…³è®¾ç½®
  ```yaml
  multi_fusion_type: "qformer"
  num_multi_query_token: 16
  frozen_multi_Qformer: False
  ```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024-11-26  
**ä½œè€…**: AffectGPT Team
