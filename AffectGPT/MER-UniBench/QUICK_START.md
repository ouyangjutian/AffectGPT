# MER-UniBench å¿«é€Ÿå…¥é—¨

## ğŸ¯ ç›®æ ‡

ä¸º9ä¸ªMER-UniBenchæ•°æ®é›†é¢„æå–Frameçš„emotion_peakç‰¹å¾ï¼Œå®ç°**æ··åˆæ¨¡å¼æ¨ç†**ï¼š
- **Frame**: é¢„æå–emotion_peakï¼ˆåŠ é€Ÿ600-1200å€ï¼‰
- **Face**: å®æ—¶uniformé‡‡æ ·
- **Audio**: å®æ—¶å¤„ç†
- **AU**: å®æ—¶CLIPç¼–ç 

---

## âš¡ ä¸‰æ­¥èµ°

### **æ­¥éª¤1ï¼šé¢„æå–Frameç‰¹å¾ï¼ˆä¸€æ¬¡æ€§ï¼Œ~3.5å°æ—¶ï¼‰**

```bash
cd /home/project/AffectGPT/AffectGPT/MER-UniBench

# è¿è¡Œæ‰¹é‡æå–
bash run_extract_emotion_peak_batch.sh
```

**è¾“å‡º**ï¼š
```
preextracted_features/
â”œâ”€â”€ mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/  (~500MB)
â”œâ”€â”€ mer2024/frame_CLIP_VIT_LARGE_emotion_peak_8frms/  (~600MB)
â”œâ”€â”€ cmumosei/...  (~2.5GB)
â”œâ”€â”€ cmumosi/...   (~2.2GB)
â”œâ”€â”€ iemocap/...   (~5GB)
â”œâ”€â”€ meld/...      (~2.6GB)
â”œâ”€â”€ ovmerdplus/... (~800MB)
â”œâ”€â”€ sims/...      (~2.3GB)
â””â”€â”€ simsv2/...    (~2.3GB)
```

---

### **æ­¥éª¤2ï¼šé…ç½®æ¨ç†ï¼ˆä½¿ç”¨æä¾›çš„æ¨¡æ¿ï¼‰**

ä½¿ç”¨å·²åˆ›å»ºçš„é…ç½®æ–‡ä»¶ï¼š
```bash
# ç¤ºä¾‹é…ç½®å·²åˆ›å»ºï¼š
ls ../eval_configs/eval_mer2023_frame_preextract.yaml
```

**å…³é”®é…ç½®**ï¼š
```yaml
datasets:
  mer2023:
    # Frameé¢„æå–
    frame_sampling: 'emotion_peak'
    use_preextracted_features: True
    preextracted_root: './preextracted_features/mer2023'
    
    # å…¶ä»–æ¨¡æ€å®æ—¶å¤„ç†
    use_au_clip_realtime: True
    mer_factory_output: '/home/project/MER-Factory/output'

model:
  skip_encoders: False  # å¿…é¡»Falseï¼ˆå®æ—¶å¤„ç†éœ€è¦ç¼–ç å™¨ï¼‰
```

---

### **æ­¥éª¤3ï¼šè¿è¡Œæ¨ç†**

```bash
cd /home/project/AffectGPT/AffectGPT

python inference_hybird.py \
    --cfg-path eval_configs/eval_mer2023_frame_preextract.yaml \
    --dataset mer2023 \
    --ckpt <your_checkpoint_path>
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [00:45<00:00, 9.12it/s]
                                      ^^^^^^^^^^^^^^^^^^^^
                                      å¿«é€Ÿï¼æ¯”å®æ—¶emotion_peakå¿«5å€
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### **MER2023 (411æ ·æœ¬)**

| æ–¹æ¡ˆ | è€—æ—¶ | å­˜å‚¨ | è¯´æ˜ |
|------|------|------|------|
| âŒ å®æ—¶emotion_peak | ~4åˆ†é’Ÿ | 0 | JSON I/Oæ…¢ |
| âœ… **Frameé¢„æå–ï¼ˆæ¨èï¼‰** | **~45ç§’** | **500MB** | **æœ¬æ–¹æ¡ˆ** |
| âš¡ å®Œå…¨é¢„æå– | ~10ç§’ | 10GB | æè‡´é€Ÿåº¦ä½†å ç”¨å¤§ |

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### **åªå¤„ç†éƒ¨åˆ†æ•°æ®é›†**

```bash
# åªæå–MER2023å’ŒMER2024
python3 extract_frame_emotion_peak_batch.py \
    --datasets mer2023 mer2024 \
    --device cuda:0
```

### **ä¿®æ”¹å…¶ä»–æ•°æ®é›†**

å¤åˆ¶å¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š
```bash
cp eval_configs/eval_mer2023_frame_preextract.yaml \
   eval_configs/eval_mer2024_frame_preextract.yaml

# ç¼–è¾‘æ–°æ–‡ä»¶ï¼Œä¿®æ”¹ï¼š
# - datasets.mer2024 (æ›¿æ¢mer2023)
# - preextracted_root: './preextracted_features/mer2024'
# - æ•°æ®è·¯å¾„
```

---

## âš ï¸ å‰ç½®è¦æ±‚

### 1. MER-Factory AUåˆ†æ

emotion_peaké‡‡æ ·ä¾èµ–MER-Factoryç”Ÿæˆçš„`au_info`ï¼š

```bash
# æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆ
ls /home/project/MER-Factory/output/mer2023/sample_*/sample_*_au_analysis.json | wc -l

# å¦‚æœæ²¡æœ‰ï¼Œè¿è¡ŒMER-Factory
cd /home/project/MER-Factory
python main.py --dataset mer2023 --modality video
```

### 2. ç£ç›˜ç©ºé—´

ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ï¼š
- å•ä¸ªæ•°æ®é›†ï¼š500MB - 5GB
- å…¨éƒ¨9ä¸ªæ•°æ®é›†ï¼š~18GB

### 3. GPUå†…å­˜

æ¨ç†éœ€è¦ï¼š
- æœ€å°: 8GBï¼ˆå•æ¨¡æ€ï¼‰
- æ¨è: 16GBï¼ˆå¤šæ¨¡æ€ï¼‰
- æœ€ä½³: 24GB+ï¼ˆå¤§batch sizeï¼‰

---

## ğŸ“ ç›®å½•ç»“æ„

```
/home/project/AffectGPT/AffectGPT/
â”œâ”€â”€ MER-UniBench/                           # æ‰¹é‡å¤„ç†å·¥å…·ç›®å½•
â”‚   â”œâ”€â”€ extract_frame_emotion_peak_batch.py # æå–è„šæœ¬
â”‚   â”œâ”€â”€ run_extract_emotion_peak_batch.sh   # Shellè„šæœ¬
â”‚   â”œâ”€â”€ QUICK_START.md                      # æœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ INFERENCE_CONFIG_GUIDE.md           # é…ç½®è¯¦è§£
â”‚   â”œâ”€â”€ EMOTION_PEAK_PREEXTRACTION_GUIDE.md # æŠ€æœ¯æ–‡æ¡£
â”‚   â””â”€â”€ README.md                           # æ€»è§ˆ
â”‚
â”œâ”€â”€ preextracted_features/                  # ç‰¹å¾è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ mer2023/
â”‚   â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”‚   â”œâ”€â”€ mer2024/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ eval_configs/                           # æ¨ç†é…ç½®ç›®å½•
â”‚   â”œâ”€â”€ eval_mer2023_frame_preextract.yaml  # ç¤ºä¾‹é…ç½®
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ inference_hybird.py                     # æ¨ç†è„šæœ¬
```

---

## â“ æ•…éšœæ’æŸ¥

### é—®é¢˜1: ç‰¹å¾æå–å¤±è´¥

```
ValueError: MER-Factory output not found
```

**è§£å†³**ï¼š
```bash
# å…ˆè¿è¡ŒMER-Factory
cd /home/project/MER-Factory
python main.py --dataset mer2023 --modality video
```

---

### é—®é¢˜2: æ¨ç†è¿˜æ˜¯å¾ˆæ…¢

```
# æ¨ç†ç”¨æ—¶: ~4åˆ†é’Ÿï¼ˆåº”è¯¥~45ç§’ï¼‰
```

**æ£€æŸ¥**ï¼š
```bash
# 1. ç‰¹å¾æ˜¯å¦å­˜åœ¨ï¼Ÿ
ls preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/*.npy | wc -l
# åº”è¯¥æ˜¾ç¤º411

# 2. é…ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ
grep -A3 "use_preextracted_features" eval_configs/eval_mer2023_frame_preextract.yaml
# åº”è¯¥æ˜¾ç¤º: use_preextracted_features: True

# 3. è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Ÿ
grep "preextracted_root" eval_configs/eval_mer2023_frame_preextract.yaml
# åº”è¯¥æ˜¯ç›¸å¯¹æˆ–ç»å¯¹æ­£ç¡®è·¯å¾„
```

---

### é—®é¢˜3: ç¼–ç å™¨é”™è¯¯

```
RuntimeError: Visual encoder is None
```

**è§£å†³**ï¼š
```yaml
# ç¡®ä¿é…ç½®ä¸­ï¼š
model:
  skip_encoders: False  # â† å¿…é¡»æ˜¯Falseï¼
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `README.md`: é¡¹ç›®æ€»è§ˆå’Œè®¾è®¡ç†å¿µ
- `INFERENCE_CONFIG_GUIDE.md`: è¯¦ç»†é…ç½®è¯´æ˜
- `EMOTION_PEAK_PREEXTRACTION_GUIDE.md`: æŠ€æœ¯åŸç†å’Œæ€§èƒ½åˆ†æ

---

## ğŸ‰ æˆåŠŸæ ‡å¿—

è¿è¡Œæ¨ç†æ—¶çœ‹åˆ°ï¼š
```
====== Inference Frame Sampling Config ======
Frame frames: 8, Frame sampling: emotion_peak
Face frames: 8, Face sampling: uniform

âœ… Frame features loaded (preextracted)
â³ Face: real-time processing
â³ Audio: real-time processing
â³ AU: real-time CLIP encoding

Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [00:45<00:00, 9.12it/s]
```

æ­å–œï¼ä½ å·²æˆåŠŸé…ç½®æ··åˆæ¨¡å¼æ¨ç† ğŸŠ
