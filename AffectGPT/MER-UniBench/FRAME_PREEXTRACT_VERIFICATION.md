# Frameé¢„æå–ç‰¹å¾éªŒè¯æŒ‡å—

## âœ… ä»£ç ä¿®å¤å®Œæˆ

### ä¿®å¤å†…å®¹

**é—®é¢˜**ï¼šåŸä»£ç æ„å»ºé¢„æå–ç‰¹å¾è·¯å¾„æ—¶ç¼ºå°‘æ•°æ®é›†åç§°å±‚çº§

**ä¿®å¤ä½ç½®**ï¼š`/home/project/AffectGPT/AffectGPT/my_affectgpt/datasets/datasets/base_dataset.py`

**ä¿®å¤å‰**ï¼ˆâŒ é”™è¯¯ï¼‰ï¼š
```python
frame_feat_path = os.path.join(preextracted_root, frame_feat_dir, f'{sample_name}.npy')
# è·¯å¾„: ./preextracted_features/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_xxx.npy âŒ
```

**ä¿®å¤å**ï¼ˆâœ… æ­£ç¡®ï¼‰ï¼š
```python
dataset_name = getattr(self, 'dataset', 'unknown')
frame_feat_path = os.path.join(preextracted_root, dataset_name.lower(), frame_feat_dir, f'{sample_name}.npy')
# è·¯å¾„: ./preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_xxx.npy âœ…
```

---

## ğŸ“‚ è·¯å¾„éªŒè¯

### å®é™…ç”Ÿæˆçš„ç‰¹å¾æ–‡ä»¶ç»“æ„

```bash
/home/project/AffectGPT/AffectGPT/preextracted_features/
â”œâ”€â”€ cmumosei/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”‚       â”œâ”€â”€ sample_xxx.npy
â”‚       â””â”€â”€ ...
â”œâ”€â”€ cmumosi/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”œâ”€â”€ iemocap/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”œâ”€â”€ meld/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”œâ”€â”€ mer2023/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”‚       â”œâ”€â”€ sample_00000008.npy
â”‚       â”œâ”€â”€ sample_00000014.npy
â”‚       â””â”€â”€ ... (411ä¸ªæµ‹è¯•é›†æ ·æœ¬)
â”œâ”€â”€ mer2024/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”œâ”€â”€ ovmerdplus/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”œâ”€â”€ sims/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â””â”€â”€ simsv2/
    â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
```

### ä»£ç åŠ è½½è·¯å¾„é€»è¾‘

```python
# åœ¨ base_dataset.py ä¸­ï¼š
preextracted_root = './preextracted_features'  # ä»é…ç½®è¯»å–
dataset_name = self.dataset.lower()  # å¦‚ 'MER2023' -> 'mer2023'
frame_feat_dir = f'frame_{visual_encoder}_{frame_sampling}_{frame_n_frms}frms'
# å¦‚ 'frame_CLIP_VIT_LARGE_emotion_peak_8frms'

frame_feat_path = os.path.join(
    preextracted_root,     # './preextracted_features'
    dataset_name,          # 'mer2023'
    frame_feat_dir,        # 'frame_CLIP_VIT_LARGE_emotion_peak_8frms'
    f'{sample_name}.npy'   # 'sample_00000008.npy'
)
# æœ€ç»ˆè·¯å¾„: ./preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_00000008.npy
```

**âœ… è·¯å¾„å®Œå…¨åŒ¹é…ï¼**

---

## ğŸ¯ æ•°æ®é›†åç§°æ˜ å°„

| æ•°æ®é›†ç±» `self.dataset` | å°å†™è½¬æ¢ `.lower()` | ç‰¹å¾ç›®å½• |
|----------------------|------------------|---------|
| `'MER2023'` | `'mer2023'` | `/preextracted_features/mer2023/` |
| `'MER2024'` | `'mer2024'` | `/preextracted_features/mer2024/` |
| `'MELD'` | `'meld'` | `/preextracted_features/meld/` |
| `'CMUMOSEI'` | `'cmumosei'` | `/preextracted_features/cmumosei/` |
| `'CMUMOSI'` | `'cmumosi'` | `/preextracted_features/cmumosi/` |
| `'IEMOCAPFour'` | `'iemocapfour'` | `/preextracted_features/iemocapfour/` âš ï¸ |
| `'SIMS'` | `'sims'` | `/preextracted_features/sims/` |
| `'SIMSv2'` | `'simsv2'` | `/preextracted_features/simsv2/` |
| `'OVMERDPlus'` | `'ovmerdplus'` | `/preextracted_features/ovmerdplus/` |

**âš ï¸ æ³¨æ„**ï¼šIEMOCAPçš„ç‰¹å¾ç›®å½•æ˜¯`iemocap`ï¼Œä½†æ•°æ®é›†ç±»æ˜¯`IEMOCAPFour`ï¼ˆå°å†™åæ˜¯`iemocapfour`ï¼‰ã€‚éœ€è¦ç¡®è®¤æå–è„šæœ¬ç”Ÿæˆçš„ç›®å½•åæ˜¯`iemocap`è¿˜æ˜¯`iemocapfour`ï¼

---

## ğŸ”§ é…ç½®éªŒè¯

### æ¨ç†é…ç½®æ–‡ä»¶ï¼ˆå·²ä¿®æ”¹ï¼‰

**æ–‡ä»¶**ï¼š`/home/project/AffectGPT/AffectGPT/train_configs/emercoarse_highlevelfilter4_outputhybird_bestsetup_bestfusion_lz_face_frame_au.yaml`

```yaml
inference:
  # Frameé…ç½®
  frame_n_frms: 8
  frame_sampling: 'emotion_peak'
  
  # âœ… Frameé¢„æå–é…ç½®
  use_preextracted_features: True
  preextracted_root: './preextracted_features'
  visual_encoder: 'CLIP_VIT_LARGE'
  
  # âœ… AUå®æ—¶CLIPç¼–ç é…ç½®
  mer_factory_output: '/home/project/MER-Factory/output'
  use_au_clip_realtime: True
```

### å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | å€¼ | ä½œç”¨ |
|-----|---|------|
| `use_preextracted_features` | `True` | å¯ç”¨Frameé¢„æå–ç‰¹å¾åŠ è½½ |
| `preextracted_root` | `'./preextracted_features'` | ç‰¹å¾æ ¹ç›®å½•ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ |
| `visual_encoder` | `'CLIP_VIT_LARGE'` | ç”¨äºæ„å»ºç‰¹å¾ç›®å½•å |
| `frame_sampling` | `'emotion_peak'` | ç”¨äºæ„å»ºç‰¹å¾ç›®å½•å |
| `frame_n_frms` | `8` | ç”¨äºæ„å»ºç‰¹å¾ç›®å½•å |
| `mer_factory_output` | `'/home/project/MER-Factory/output'` | AUæ¨¡æ€éœ€è¦ï¼ˆè¯»å–summary_descriptionï¼‰ |

---

## ğŸš€ ä½¿ç”¨æµç¨‹

### 1. éªŒè¯ç‰¹å¾æ–‡ä»¶å·²ç”Ÿæˆ

```bash
# æ£€æŸ¥MER2023ç‰¹å¾æ–‡ä»¶
ls -l /home/project/AffectGPT/AffectGPT/preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/ | wc -l
# åº”è¯¥æœ‰ 412 è¡Œï¼ˆ411ä¸ªæ ·æœ¬ + 1è¡Œæ ‡é¢˜ï¼‰

# æ£€æŸ¥å•ä¸ªæ–‡ä»¶å†…å®¹
python3 -c "
import numpy as np
feat = np.load('/home/project/AffectGPT/AffectGPT/preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_00000008.npy')
print(f'Shape: {feat.shape}')  # åº”è¯¥æ˜¯ (8, 768)
print(f'Dtype: {feat.dtype}')  # åº”è¯¥æ˜¯ float32
"
```

### 2. è¿è¡Œæ¨ç†

```bash
cd /home/project/AffectGPT/AffectGPT

python inference_hybird.py \
    --cfg-path train_configs/emercoarse_highlevelfilter4_outputhybird_bestsetup_bestfusion_lz_face_frame_au.yaml \
    --dataset mer2023 \
    --ckpt <your_checkpoint_path>
```

### 3. éªŒè¯åŠ è½½è¡Œä¸º

**é¢„æœŸè¾“å‡º**ï¼ˆé¦–æ¬¡åŠ è½½æ—¶ï¼‰ï¼š
```
[INFERENCE] Frame frames: 8, Frame sampling: emotion_peak
[INFERENCE] AUæ¨¡å¼: CLIPå®æ—¶ç¼–ç æ¨¡å¼ï¼ˆä»MER-Factory JSONåŠ è½½summary_descriptionï¼‰
```

**å¦‚æœçœ‹åˆ°è­¦å‘Š**ï¼š
```
âš ï¸ Frameé¢„æå–ç‰¹å¾ä¸å­˜åœ¨: ./preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_xxx.npy
   å°†å›é€€åˆ°å®æ—¶å¤„ç†æ¨¡å¼
```

è¿™è¯´æ˜ï¼š
- ç‰¹å¾æ–‡ä»¶è·¯å¾„ä¸å¯¹
- ç‰¹å¾æ–‡ä»¶æœªç”Ÿæˆ
- æ ·æœ¬åä¸åŒ¹é…

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šç‰¹å¾æ–‡ä»¶è·¯å¾„ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼šæ€»æ˜¯æ˜¾ç¤º"Frameé¢„æå–ç‰¹å¾ä¸å­˜åœ¨"

**æ£€æŸ¥**ï¼š
```bash
# æ‰“å°å®é™…è·¯å¾„
python3 -c "
import os
preextracted_root = './preextracted_features'
dataset_name = 'mer2023'
frame_feat_dir = 'frame_CLIP_VIT_LARGE_emotion_peak_8frms'
sample_name = 'sample_00000008'
path = os.path.join(preextracted_root, dataset_name, frame_feat_dir, f'{sample_name}.npy')
print(f'æœŸæœ›è·¯å¾„: {path}')
print(f'æ˜¯å¦å­˜åœ¨: {os.path.exists(path)}')
"
```

**è§£å†³**ï¼š
- ç¡®ä¿ä»`/home/project/AffectGPT/AffectGPT`ç›®å½•è¿è¡Œæ¨ç†
- æˆ–ä¿®æ”¹é…ç½®ä¸ºç»å¯¹è·¯å¾„ï¼š`preextracted_root: '/home/project/AffectGPT/AffectGPT/preextracted_features'`

### é—®é¢˜2ï¼šIEMOCAPç›®å½•åä¸åŒ¹é…

**ç—‡çŠ¶**ï¼šIEMOCAPæ‰¾ä¸åˆ°ç‰¹å¾æ–‡ä»¶

**åŸå› **ï¼š
- æå–è„šæœ¬ç”Ÿæˆç›®å½•ï¼š`iemocap`
- æ•°æ®é›†ç±»åç§°ï¼š`IEMOCAPFour` â†’ å°å†™å `iemocapfour`

**æ£€æŸ¥**ï¼š
```bash
ls /home/project/AffectGPT/AffectGPT/preextracted_features/ | grep -i iemocap
```

**è§£å†³**ï¼š
- å¦‚æœç›®å½•æ˜¯`iemocap`ï¼Œéœ€è¦é‡å‘½åä¸º`iemocapfour`
- æˆ–ä¿®æ”¹æ•°æ®é›†ç±»çš„`self.dataset = 'IEMOCAP'`ï¼ˆè€Œä¸æ˜¯`'IEMOCAPFour'`ï¼‰

### é—®é¢˜3ï¼šç‰¹å¾ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼šåŠ è½½ç‰¹å¾åæ¨¡å‹æŠ¥é”™

**æ£€æŸ¥**ï¼š
```bash
python3 -c "
import numpy as np
import glob
files = glob.glob('/home/project/AffectGPT/AffectGPT/preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/*.npy')[:5]
for f in files:
    feat = np.load(f)
    print(f'{f}: {feat.shape}')
"
```

**é¢„æœŸ**ï¼šæ‰€æœ‰ç‰¹å¾åº”è¯¥æ˜¯ `(8, 768)`

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### FrameåŠ è½½æ—¶é—´å¯¹æ¯”

| æ¨¡å¼ | åŠ è½½æ–¹å¼ | æ—¶é—´/æ ·æœ¬ | åŠ é€Ÿæ¯” |
|------|---------|---------|-------|
| **å®æ—¶emotion_peak** | è¯»å–è§†é¢‘ + è¯»å–AU JSON + è®¡ç®—ç´¢å¼• + è§£ç 8å¸§ + CLIPç¼–ç  | ~5-10ms | 1x |
| **é¢„æå–emotion_peak** | ç›´æ¥np.load() | ~0.5ms | **10-20x** âš¡ |

### æ€»ä½“æ¨ç†åŠ é€Ÿ

å‡è®¾å•æ ·æœ¬æ¨ç†æ—¶é—´åˆ†å¸ƒï¼š
- FrameåŠ è½½ï¼ˆemotion_peakå®æ—¶ï¼‰: 8ms
- FaceåŠ è½½: 0.01ms
- AudioåŠ è½½: 15ms
- AUå¤„ç†: 2ms
- æ¨¡å‹æ¨ç†: 50ms
- **æ€»è®¡**: ~75ms

ä¼˜åŒ–åï¼š
- FrameåŠ è½½ï¼ˆé¢„æå–ï¼‰: 0.5ms âœ…
- FaceåŠ è½½: 0.01ms
- AudioåŠ è½½: 15ms
- AUå¤„ç†: 2ms
- æ¨¡å‹æ¨ç†: 50ms
- **æ€»è®¡**: ~67.5ms

**åŠ é€Ÿæ•ˆæœ**: ~10% æ€»ä½“åŠ é€Ÿï¼ŒFrameæ¨¡å—åŠ é€Ÿ **16å€**

---

## âœ… éªŒè¯æ¸…å•

æ¨ç†å‰è¯·ç¡®è®¤ï¼š

- [x] é¢„æå–ç‰¹å¾æ–‡ä»¶å·²ç”Ÿæˆï¼ˆè¿è¡Œ`run_extract_emotion_peak_batch.sh`ï¼‰
- [x] é…ç½®æ–‡ä»¶å·²ä¿®æ”¹ï¼ˆ`use_preextracted_features: True`ï¼‰
- [x] ä»£ç å·²ä¿®å¤ï¼ˆ`base_dataset.py`æ·»åŠ æ•°æ®é›†åç§°å±‚çº§ï¼‰
- [x] è·¯å¾„åŒ¹é…éªŒè¯ï¼ˆç‰¹å¾æ–‡ä»¶è·¯å¾„ä¸ä»£ç æ„å»ºè·¯å¾„ä¸€è‡´ï¼‰
- [x] MER-Factoryè¾“å‡ºå­˜åœ¨ï¼ˆAUæ¨¡æ€éœ€è¦ï¼‰
- [ ] è¿è¡Œæ¨ç†å¹¶è§‚å¯Ÿæ˜¯å¦æœ‰"Frameé¢„æå–ç‰¹å¾ä¸å­˜åœ¨"è­¦å‘Š
- [ ] éªŒè¯æ¨ç†é€Ÿåº¦æå‡

---

## ğŸ“ æ€»ç»“

**å·²å®Œæˆ**ï¼š
1. âœ… ä¿®å¤`base_dataset.py`è·¯å¾„æ„å»ºé€»è¾‘ï¼ˆæ·»åŠ æ•°æ®é›†åç§°å±‚çº§ï¼‰
2. âœ… æ·»åŠ é¢„æå–ç‰¹å¾å›é€€æœºåˆ¶ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å®æ—¶æ¨¡å¼ï¼‰
3. âœ… ä¿®æ”¹æ¨ç†é…ç½®æ–‡ä»¶ï¼ˆå¯ç”¨Frameé¢„æå–ï¼‰
4. âœ… éªŒè¯ç‰¹å¾æ–‡ä»¶è·¯å¾„ä¸ä»£ç é€»è¾‘åŒ¹é…

**å¾…éªŒè¯**ï¼š
- IEMOCAPç›®å½•åæ˜¯å¦åŒ¹é…ï¼ˆ`iemocap` vs `iemocapfour`ï¼‰
- å®é™…æ¨ç†è¿è¡Œæ˜¯å¦èƒ½æˆåŠŸåŠ è½½é¢„æå–ç‰¹å¾
- æ¨ç†é€Ÿåº¦æå‡æ•ˆæœ

**æ¨èä¸‹ä¸€æ­¥**ï¼š
è¿è¡Œä¸€ä¸ªå°æ‰¹é‡æ¨ç†æµ‹è¯•ï¼ŒéªŒè¯FeatureåŠ è½½æ˜¯å¦æ­£å¸¸ï¼š
```bash
cd /home/project/AffectGPT/AffectGPT
python inference_hybird.py \
    --cfg-path train_configs/emercoarse_highlevelfilter4_outputhybird_bestsetup_bestfusion_lz_face_frame_au.yaml \
    --dataset mer2023 \
    --ckpt <checkpoint> \
    2>&1 | grep -E "(Frame|é¢„æå–|preextract)" | head -20
```

è§‚å¯Ÿè¾“å‡ºä¸­æ˜¯å¦æœ‰"Frameé¢„æå–ç‰¹å¾ä¸å­˜åœ¨"è­¦å‘Šã€‚å¦‚æœæ²¡æœ‰è­¦å‘Šï¼Œè¯´æ˜åŠ è½½æˆåŠŸï¼ğŸ‰
