#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ºMER-UniBench 9ä¸ªæ•°æ®é›†æ‰¹é‡é¢„æå–emotion_peaké‡‡æ ·çš„Frameç‰¹å¾
é¿å…æ¨ç†æ—¶çš„å®æ—¶æ–‡ä»¶I/Oå¼€é”€

æ”¯æŒæ•°æ®é›†:
- CMUMOSEI, CMUMOSI, IEMOCAP, MELD
- MER2023, MER2024
- OVMERDPLUS, SIMS, SIMSv2
"""

import os
import sys
import argparse
import numpy as np
import torch
from tqdm import tqdm
from pathlib import Path
import json
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ è·¯å¾„ï¼ˆè„šæœ¬åœ¨MER-UniBenchå­ç›®å½•ï¼Œéœ€è¦æ·»åŠ ä¸Šçº§ç›®å½•ï¼‰
script_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(script_dir)  # AffectGPTæ ¹ç›®å½•
sys.path.insert(0, parent_dir)
sys.path.insert(0, os.path.join(parent_dir, 'my_affectgpt'))

from my_affectgpt.common.registry import registry
from my_affectgpt.processors.video_processor import load_video
import config


# æ•°æ®é›†é…ç½®ï¼ˆåŸºäºMER-Factoryçš„batch_extract_au_multi_datasets.pyé…ç½®ï¼‰
# LinuxæœåŠ¡å™¨è·¯å¾„
DATASET_ROOT = "/home/project/Dataset/Emotion/MER2025/dataset"

DATASET_CONFIGS = {
    'cmumosei': {
        'video_root': f'{DATASET_ROOT}/cmumosei-process/subvideo_new',
        'label_file': f'{DATASET_ROOT}/cmumosei-process/label.npz',
        'label_type': 'npz',
        'corpus_key': 'test_corpus',  # æ¨ç†ä½¿ç”¨æµ‹è¯•é›†
        'video_ext': '.mp4',
        'mer_factory': 'CMUMOSEI'
    },
    'cmumosi': {
        'video_root': f'{DATASET_ROOT}/cmumosi-process/subvideo',
        'label_file': f'{DATASET_ROOT}/cmumosi-process/label.npz',
        'label_type': 'npz',
        'corpus_key': 'test_corpus',
        'video_ext': '.mp4',
        'mer_factory': 'CMUMOSI'
    },
    'iemocap': {
        'video_root': f'{DATASET_ROOT}/iemocap-process/subvideo-tgt',
        'label_file': f'{DATASET_ROOT}/iemocap-process/label_4way.npz',
        'label_type': 'npz',
        'corpus_key': 'whole_corpus',  # IEMOCAPç‰¹æ®Šï¼šä½¿ç”¨whole_corpus
        'session_filter': 'Ses05',  # åªå¤„ç†Ses05ï¼ˆæµ‹è¯•é›†ï¼‰
        'video_ext': '.avi',
        'mer_factory': 'IEMOCAPFour'
    },
    'meld': {
        'video_root': f'{DATASET_ROOT}/meld-process/subvideo',
        'label_file': f'{DATASET_ROOT}/meld-process/label.npz',
        'label_type': 'npz',
        'corpus_key': 'test_corpus',
        'video_ext': '.mp4',
        'mer_factory': 'MELD'
    },
    'mer2023': {
        'video_root': f'{DATASET_ROOT}/mer2023-dataset-process/video',
        'label_file': f'{DATASET_ROOT}/mer2023-dataset-process/label-6way.npz',
        'label_type': 'npz',
        'corpus_key': 'test1_corpus',  # æ¨ç†ä½¿ç”¨test1
        'video_ext': '.mp4',
        'mer_factory': 'MER2023'
    },
    'mer2024': {
        'video_root': f'{DATASET_ROOT}/mer2024-dataset-process/video',
        'label_file': f'{DATASET_ROOT}/mer2024-dataset-process/label-6way.npz',
        'label_type': 'npz',
        'corpus_key': 'test1_corpus',
        'video_ext': '.mp4',
        'mer_factory': 'MER2024'
    },
    'ovmerdplus': {
        'video_root': f'{DATASET_ROOT}/ovmerdplus-process/video',
        'label_file': f'{DATASET_ROOT}/ovmerdplus-process/subtitle_eng.csv',  # æµ‹è¯•é›†ç”¨subtitle_eng.csv
        'label_type': 'csv',
        'name_column': 'name',
        'video_ext': '.mp4',
        'mer_factory': 'OVMERDPlus'
    },
    'sims': {
        'video_root': f'{DATASET_ROOT}/sims-process/video',
        'label_file': f'{DATASET_ROOT}/sims-process/label.npz',
        'label_type': 'npz',
        'corpus_key': 'test_corpus',
        'video_ext': '.mp4',
        'mer_factory': 'SIMS'
    },
    'simsv2': {
        'video_root': f'{DATASET_ROOT}/simsv2-process/video_new',
        'label_file': f'{DATASET_ROOT}/simsv2-process/label.npz',
        'label_type': 'npz',
        'corpus_key': 'test_corpus',
        'video_ext': '.mp4',
        'mer_factory': 'SIMSv2'
    }
}


def load_sample_names(dataset_name, label_file, dataset_config):
    """ä»æ ‡ç­¾æ–‡ä»¶åŠ è½½æ ·æœ¬åç§°åˆ—è¡¨
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        label_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        dataset_config: æ•°æ®é›†é…ç½®ï¼ˆåŒ…å«label_type, corpus_keyç­‰ï¼‰
    """
    label_type = dataset_config.get('label_type', 'json')
    
    if label_type == 'csv' or label_file.endswith('.csv'):
        # CSVæ ¼å¼ï¼ˆå¦‚OVMERDPlusï¼‰
        import pandas as pd
        df = pd.read_csv(label_file)
        name_column = dataset_config.get('name_column', 'name')
        samples = df[name_column].dropna().tolist()
    elif label_type == 'npz' or label_file.endswith('.npz'):
        # NPZæ ¼å¼
        data = np.load(label_file, allow_pickle=True)
        corpus_key = dataset_config.get('corpus_key', 'test_corpus')
        
        if corpus_key in data:
            corpus_data = data[corpus_key].item()
            if isinstance(corpus_data, dict):
                all_samples = list(corpus_data.keys())
                
                # IEMOCAPç‰¹æ®Šå¤„ç†ï¼šé€šè¿‡sessionè¿‡æ»¤
                if dataset_name == 'iemocap' and 'session_filter' in dataset_config:
                    session_filter = dataset_config['session_filter']
                    samples = [s for s in all_samples if s.startswith(session_filter)]
                else:
                    samples = all_samples
            else:
                samples = []
        else:
            print(f"âš ï¸  Warning: corpus_key '{corpus_key}' not found in {label_file}")
            samples = []
    elif label_file.endswith('.json'):
        # JSONæ ¼å¼
        with open(label_file, 'r') as f:
            data = json.load(f)
        if 'test' in data:
            samples = list(data['test'].keys())
        else:
            samples = list(data.keys())
    else:
        raise ValueError(f"Unsupported label file format: {label_file}")
    
    return samples


def extract_frame_features_emotion_peak(
    dataset_name,
    video_root,
    sample_names,
    output_dir,
    visual_encoder,
    mer_factory_output,
    n_frms=8,
    device='cuda:0',
    quiet=False
):
    """
    æå–emotion_peaké‡‡æ ·çš„Frameç‰¹å¾
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        video_root: è§†é¢‘æ ¹ç›®å½•
        sample_names: æ ·æœ¬åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        visual_encoder: è§†è§‰ç¼–ç å™¨å®ä¾‹
        mer_factory_output: MER-Factoryè¾“å‡ºæ ¹ç›®å½•
        n_frms: é‡‡æ ·å¸§æ•°
        device: è®¾å¤‡
        quiet: æ˜¯å¦é™é»˜æ¨¡å¼
    """
    os.makedirs(output_dir, exist_ok=True)
    
    success_count = 0
    skip_count = 0
    error_count = 0
    errors = []
    
    # æ„å»ºMER-Factoryæ•°æ®é›†è·¯å¾„
    mer_factory_dataset_path = os.path.join(mer_factory_output, DATASET_CONFIGS[dataset_name]['mer_factory'])
    
    for sample_name in tqdm(sample_names, desc=f"Extracting {dataset_name} Frame (emotion_peak)", disable=quiet):
        output_file = os.path.join(output_dir, f'{sample_name}.npy')
        
        # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
        if os.path.exists(output_file):
            skip_count += 1
            continue
        
        try:
            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
            video_path = None
            for ext in ['.mp4', '.avi', '.mkv', '.mov']:
                candidate = os.path.join(video_root, f'{sample_name}{ext}')
                if os.path.exists(candidate):
                    video_path = candidate
                    break
            
            if not video_path:
                raise FileNotFoundError(f"Video not found for {sample_name}")
            
            # ä½¿ç”¨emotion_peaké‡‡æ ·åŠ è½½è§†é¢‘å¸§
            # ä¼ é€’video_nameå’Œmer_factory_outputä»¥å¯ç”¨æ™ºèƒ½é‡‡æ ·
            raw_frames, msg = load_video(
                video_path=video_path,
                n_frms=n_frms,
                height=224,
                width=224,
                sampling='emotion_peak',  # ğŸ¯ å…³é”®ï¼šä½¿ç”¨emotion_peaké‡‡æ ·
                return_msg=True,
                video_name=sample_name,  # ä¼ é€’æ ·æœ¬å
                mer_factory_output=mer_factory_dataset_path  # ä¼ é€’MER-Factoryè·¯å¾„
            )
            
            # è½¬æ¢ä¸ºCLIPæ ¼å¼ [C, T, H, W]
            if raw_frames.dim() == 4:  # [C, T, H, W]
                frames = raw_frames.unsqueeze(0).to(device)  # [1, C, T, H, W]
            else:
                raise ValueError(f"Unexpected frame shape: {raw_frames.shape}")
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                # CLIPç¼–ç å™¨è¾“å‡º: [1, T, 768]
                features = visual_encoder(frames, frames)  # (video, raw_video)
                
                # è½¬ä¸ºnumpyå¹¶å»æ‰batchç»´åº¦
                features_np = features.squeeze(0).cpu().numpy()  # [T, 768]
            
            # ä¿å­˜ç‰¹å¾
            np.save(output_file, features_np)
            success_count += 1
            
        except Exception as e:
            error_count += 1
            error_msg = f"{sample_name}: {str(e)}"
            errors.append(error_msg)
            if not quiet and error_count <= 5:  # åªæ‰“å°å‰5ä¸ªé”™è¯¯
                print(f"  âš ï¸  {error_msg}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    if not quiet:
        print(f"\n{'='*70}")
        print(f"âœ… {dataset_name.upper()} Frame (emotion_peak) Extraction Complete")
        print(f"{'='*70}")
        print(f"  Success: {success_count}")
        print(f"  Skipped: {skip_count} (already exists)")
        print(f"  Errors:  {error_count}")
        if error_count > 0:
            print(f"\n  First {min(5, len(errors))} errors:")
            for err in errors[:5]:
                print(f"    - {err}")
        print(f"{'='*70}\n")
    
    return success_count, skip_count, error_count


def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡é¢„æå–MER-UniBenchæ•°æ®é›†çš„emotion_peak Frameç‰¹å¾')
    parser.add_argument('--datasets', type=str, nargs='+', 
                       default=['cmumosei', 'cmumosi', 'iemocap', 'meld', 'mer2023', 'mer2024', 'ovmerdplus', 'sims', 'simsv2'],
                       help='è¦å¤„ç†çš„æ•°æ®é›†åˆ—è¡¨')
    parser.add_argument('--output-root', type=str, default='./preextracted_features',
                       help='ç‰¹å¾è¾“å‡ºæ ¹ç›®å½•')
    parser.add_argument('--mer-factory-output', type=str, default='/home/project/MER-Factory/output',
                       help='MER-Factoryè¾“å‡ºæ ¹ç›®å½•ï¼ˆåŒ…å«au_infoï¼‰')
    parser.add_argument('--visual-encoder', type=str, default='CLIP_VIT_LARGE',
                       help='è§†è§‰ç¼–ç å™¨åç§°')
    parser.add_argument('--n-frms', type=int, default=8,
                       help='é‡‡æ ·å¸§æ•°')
    parser.add_argument('--device', type=str, default='cuda:0',
                       help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--quiet', action='store_true',
                       help='é™é»˜æ¨¡å¼')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥MER-Factoryè·¯å¾„
    if not os.path.exists(args.mer_factory_output):
        print(f"âŒ MER-Factory output directory not found: {args.mer_factory_output}")
        print(f"   emotion_peaké‡‡æ ·éœ€è¦MER-Factoryç”Ÿæˆçš„au_info")
        print(f"   è¯·å…ˆè¿è¡ŒMER-Factoryå¤„ç†è¿™äº›æ•°æ®é›†")
        return
    
    print(f"\n{'='*70}")
    print("ğŸš€ MER-UniBench Frame Emotion_Peak Feature Extraction")
    print(f"{'='*70}\n")
    print(f"ğŸ“Š Datasets: {', '.join(args.datasets)}")
    print(f"ğŸ“ Output root: {args.output_root}")
    print(f"ğŸ¯ Sampling strategy: emotion_peak (based on au_info)")
    print(f"ğŸ“‚ MER-Factory output: {args.mer_factory_output}")
    print(f"ğŸ”§ Visual encoder: {args.visual_encoder}")
    print(f"ğŸ¬ Frames per sample: {args.n_frms}")
    print(f"ğŸ’» Device: {args.device}\n")
    
    # åŠ è½½è§†è§‰ç¼–ç å™¨ï¼ˆåªéœ€åŠ è½½ä¸€æ¬¡ï¼‰
    print("ğŸ”§ Loading Visual Encoder...")
    encoder_cls = registry.get_visual_encoder_class(args.visual_encoder)
    visual_encoder = encoder_cls().to(args.device)
    visual_encoder.eval()
    print("âœ… Visual Encoder loaded\n")
    
    # å¤„ç†æ¯ä¸ªæ•°æ®é›†
    total_stats = {'success': 0, 'skip': 0, 'error': 0}
    
    for dataset_name in args.datasets:
        if dataset_name not in DATASET_CONFIGS:
            print(f"âš ï¸  Unknown dataset: {dataset_name}, skipping...")
            continue
        
        config = DATASET_CONFIGS[dataset_name]
        
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
        if not os.path.exists(config['video_root']):
            print(f"âš ï¸  Video root not found for {dataset_name}: {config['video_root']}, skipping...")
            continue
        
        if not os.path.exists(config['label_file']):
            print(f"âš ï¸  Label file not found for {dataset_name}: {config['label_file']}, skipping...")
            continue
        
        # åŠ è½½æ ·æœ¬åç§°
        sample_names = load_sample_names(dataset_name, config['label_file'], config)
        
        # æ„å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(
            args.output_root,
            dataset_name,
            f'frame_{args.visual_encoder}_emotion_peak_{args.n_frms}frms'
        )
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ Processing {dataset_name.upper()}")
        print(f"{'='*70}")
        print(f"  Video root: {config['video_root']}")
        print(f"  Samples: {len(sample_names)}")
        print(f"  Output: {output_dir}")
        print(f"  MER-Factory: {os.path.join(args.mer_factory_output, config['mer_factory'])}\n")
        
        # æå–ç‰¹å¾
        success, skip, error = extract_frame_features_emotion_peak(
            dataset_name=dataset_name,
            video_root=config['video_root'],
            sample_names=sample_names,
            output_dir=output_dir,
            visual_encoder=visual_encoder,
            mer_factory_output=args.mer_factory_output,
            n_frms=args.n_frms,
            device=args.device,
            quiet=args.quiet
        )
        
        total_stats['success'] += success
        total_stats['skip'] += skip
        total_stats['error'] += error
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*70}")
    print("ğŸ‰ All Datasets Processed")
    print(f"{'='*70}")
    print(f"  Total Success: {total_stats['success']}")
    print(f"  Total Skipped: {total_stats['skip']}")
    print(f"  Total Errors:  {total_stats['error']}")
    print(f"{'='*70}\n")
    
    print("ğŸ’¡ Usage:")
    print("   åœ¨æ¨ç†é…ç½®ä¸­è®¾ç½®:")
    print("   - frame_sampling: 'emotion_peak'")
    print("   - use_preextracted_features: True")
    print("   - preextracted_root: './preextracted_features/<dataset_name>'")
    print()


if __name__ == '__main__':
    main()
