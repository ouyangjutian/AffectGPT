# Emotion Peaké‡‡æ ·ç‰¹å¾é¢„æå–æŒ‡å—

## ğŸ“‹ èƒŒæ™¯

åœ¨æ¨ç†æ—¶ä½¿ç”¨`emotion_peak`é‡‡æ ·ä¼šæ¯”`uniform`é‡‡æ ·æ…¢**500-1000å€**ï¼Œä¸»è¦åŸå› ï¼š
- æ¯ä¸ªæ ·æœ¬éƒ½éœ€è¦è¯»å–JSONæ–‡ä»¶ï¼ˆ~0.3msï¼‰
- æ–‡ä»¶ç³»ç»ŸI/Oæ£€æŸ¥ï¼ˆ~5-10msï¼‰
- å¤æ‚çš„ç´¢å¼•è®¡ç®—é€»è¾‘ï¼ˆ~0.05msï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼šé¢„å…ˆæå–`emotion_peak`é‡‡æ ·çš„ç‰¹å¾å¹¶ä¿å­˜ä¸º`.npy`æ–‡ä»¶ï¼Œæ¨ç†æ—¶ç›´æ¥åŠ è½½ã€‚

---

## ğŸ¯ æ”¯æŒçš„æ•°æ®é›†

MER-UniBench 9ä¸ªæ•°æ®é›†ï¼š
1. **CMU-MOSEI**
2. **CMU-MOSI**
3. **IEMOCAP**
4. **MELD**
5. **MER2023**
6. **MER2024**
7. **OVMERD+**
8. **SIMS**
9. **SIMSv2**

---

## âš™ï¸ å‰ç½®è¦æ±‚

### 1. MER-Factory AUåˆ†æç»“æœ

`emotion_peak`é‡‡æ ·ä¾èµ–MER-Factoryç”Ÿæˆçš„`au_info`ï¼ˆæƒ…æ„Ÿå³°å€¼å¸§ä¿¡æ¯ï¼‰ã€‚

**æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆ**ï¼š
```bash
ls /home/project/MER-Factory/output/mer2023/
# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ sample_XXXXXXXX/sample_XXXXXXXX_au_analysis.json çš„æ–‡ä»¶
```

**å¦‚æœæœªç”Ÿæˆï¼Œéœ€è¦å…ˆè¿è¡ŒMER-Factory**ï¼š
```bash
cd /home/project/MER-Factory

# å¤„ç†å•ä¸ªæ•°æ®é›†
python main.py --dataset mer2023 --modality video

# æ‰¹é‡å¤„ç†9ä¸ªæ•°æ®é›†
for dataset in cmumosei cmumosi iemocap meld mer2023 mer2024 ovmerdplus sims simsv2; do
    echo "Processing $dataset..."
    python main.py --dataset $dataset --modality video
done
```

### 2. ç£ç›˜ç©ºé—´

æ¯ä¸ªæ•°æ®é›†çš„ç‰¹å¾æ–‡ä»¶å¤§å°ï¼ˆemotion_peak 8å¸§ï¼‰ï¼š
- **MER2023**: ~500MB (411 samples)
- **MER2024**: ~600MB (500 samples)
- **CMU-MOSEI**: ~2.5GB (2,500 samples)
- **å…¶ä»–æ•°æ®é›†**: æ ¹æ®æ ·æœ¬æ•°é‡è€Œå®š

**æ€»è®¡çº¦5-8GB** for all 9 datasets.

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1ï¼šä½¿ç”¨Shellè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/project/AffectGPT/AffectGPT

# èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x run_extract_emotion_peak_batch.sh

# è¿è¡Œæ‰¹é‡æå–
bash run_extract_emotion_peak_batch.sh
```

**è„šæœ¬ä¼šè‡ªåŠ¨**ï¼š
- âœ… æ£€æŸ¥MER-Factoryè¾“å‡ºæ˜¯å¦å­˜åœ¨
- âœ… æ˜¾ç¤ºæ¯ä¸ªæ•°æ®é›†çš„å¤„ç†çŠ¶æ€
- âœ… æ‰¹é‡æå–æ‰€æœ‰9ä¸ªæ•°æ®é›†çš„ç‰¹å¾
- âœ… æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å’Œè€—æ—¶

### æ–¹æ³•2ï¼šä½¿ç”¨Pythonè„šæœ¬

```bash
cd /home/project/AffectGPT/AffectGPT

# æå–æ‰€æœ‰9ä¸ªæ•°æ®é›†
python extract_frame_emotion_peak_batch.py \
    --datasets cmumosei cmumosi iemocap meld mer2023 mer2024 ovmerdplus sims simsv2 \
    --output-root ./preextracted_features \
    --mer-factory-output /home/project/MER-Factory/output \
    --visual-encoder CLIP_VIT_LARGE \
    --n-frms 8 \
    --device cuda:0

# æˆ–åªæå–ç‰¹å®šæ•°æ®é›†
python extract_frame_emotion_peak_batch.py \
    --datasets mer2023 mer2024 \
    --device cuda:0
```

### å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--datasets` | æ‰€æœ‰9ä¸ªæ•°æ®é›† | è¦å¤„ç†çš„æ•°æ®é›†åˆ—è¡¨ |
| `--output-root` | `./preextracted_features` | ç‰¹å¾è¾“å‡ºæ ¹ç›®å½• |
| `--mer-factory-output` | `/home/project/MER-Factory/output` | MER-Factoryè¾“å‡ºç›®å½• |
| `--visual-encoder` | `CLIP_VIT_LARGE` | è§†è§‰ç¼–ç å™¨åç§° |
| `--n-frms` | `8` | é‡‡æ ·å¸§æ•° |
| `--device` | `cuda:0` | è®¡ç®—è®¾å¤‡ |
| `--quiet` | `False` | é™é»˜æ¨¡å¼ |

---

## ğŸ“‚ è¾“å‡ºç»“æ„

æå–å®Œæˆåï¼Œç‰¹å¾æ–‡ä»¶å°†ä¿å­˜åœ¨ï¼š
```
./preextracted_features/
â”œâ”€â”€ mer2023/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”‚       â”œâ”€â”€ sample_00000001.npy  # [8, 768]
â”‚       â”œâ”€â”€ sample_00000002.npy
â”‚       â””â”€â”€ ...
â”œâ”€â”€ mer2024/
â”‚   â””â”€â”€ frame_CLIP_VIT_LARGE_emotion_peak_8frms/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ cmumosei/
â”œâ”€â”€ cmumosi/
â”œâ”€â”€ iemocap/
â”œâ”€â”€ meld/
â”œâ”€â”€ ovmerdplus/
â”œâ”€â”€ sims/
â””â”€â”€ simsv2/
```

æ¯ä¸ª`.npy`æ–‡ä»¶ï¼š
- **å½¢çŠ¶**: `[8, 768]` (8å¸§ Ã— 768ç»´CLIPç‰¹å¾)
- **å¤§å°**: ~24KB per sample
- **é‡‡æ ·**: åŸºäºau_infoçš„emotion_peakæ™ºèƒ½é‡‡æ ·

---

## ğŸ”§ æ¨ç†æ—¶ä½¿ç”¨é¢„æå–ç‰¹å¾

### ä¿®æ”¹æ¨ç†é…ç½®æ–‡ä»¶

ç¼–è¾‘ `eval_configs/eval_<dataset>.yaml`ï¼š

```yaml
datasets:
  mer2023:
    data_type: video
    face_or_frame: 'frame'  # æˆ–å…¶ä»–ç»„åˆ
    
    # ğŸ¯ å…³é”®é…ç½®ï¼šä½¿ç”¨é¢„æå–çš„emotion_peakç‰¹å¾
    frame_sampling: 'emotion_peak'           # â† æŒ‡å®šé‡‡æ ·ç­–ç•¥
    use_preextracted_features: True          # â† å¯ç”¨é¢„æå–æ¨¡å¼
    preextracted_root: './preextracted_features/mer2023'  # â† ç‰¹å¾è·¯å¾„
    
    # ç¼–ç å™¨é…ç½®ï¼ˆç”¨äºæ„å»ºç‰¹å¾è·¯å¾„ï¼‰
    visual_encoder: 'CLIP_VIT_LARGE'
    frame_n_frms: 8
```

### è·¯å¾„æ„å»ºé€»è¾‘

ç³»ç»Ÿä¼šè‡ªåŠ¨æ ¹æ®é…ç½®æ„å»ºç‰¹å¾è·¯å¾„ï¼š
```python
# base_dataset.py ç¬¬459è¡Œ
frame_feat_dir = f'frame_{visual_encoder}_{frame_sampling}_{frame_n_frms}frms'
# ç”Ÿæˆ: frame_CLIP_VIT_LARGE_emotion_peak_8frms

frame_feat_path = os.path.join(preextracted_root, frame_feat_dir, f'{sample_name}.npy')
# å®Œæ•´è·¯å¾„: ./preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_00000001.npy
```

### è¿è¡Œæ¨ç†

```bash
cd /home/project/AffectGPT/AffectGPT

python inference_hybird.py \
    --cfg-path eval_configs/eval_mer2023.yaml \
    --dataset mer2023 \
    --ckpt <checkpoint_path>
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å®æ—¶emotion_peaké‡‡æ ·ï¼ˆæœªé¢„æå–ï¼‰
- **å•æ ·æœ¬**: 5-10msï¼ˆæ–‡ä»¶I/O + JSONè§£æ + ç´¢å¼•è®¡ç®—ï¼‰
- **411æ ·æœ¬ï¼ˆMER2023ï¼‰**: ~2-4åˆ†é’Ÿ
- **ç“¶é¢ˆ**: æ–‡ä»¶ç³»ç»ŸI/O

### é¢„æå–emotion_peakç‰¹å¾
- **å•æ ·æœ¬**: ~0.5msï¼ˆç›´æ¥åŠ è½½.npyï¼‰
- **411æ ·æœ¬ï¼ˆMER2023ï¼‰**: ~0.2ç§’
- **é€Ÿåº¦æå‡**: **600-1200å€** âš¡

### å¯¹æ¯”uniformé‡‡æ ·
- **æ€§èƒ½**: ä¸uniformé¢„æå–ç›¸å½“ï¼ˆéƒ½æ˜¯ç›´æ¥åŠ è½½.npyï¼‰
- **ç²¾åº¦**: å¯èƒ½ç•¥é«˜ï¼ˆæ™ºèƒ½é€‰æ‹©æƒ…æ„Ÿå³°å€¼å¸§ï¼‰
- **å­˜å‚¨**: ç›¸åŒï¼ˆéƒ½æ˜¯8å¸§Ã—768ç»´ï¼‰

---

## â±ï¸ æå–è€—æ—¶ä¼°ç®—

åŸºäºNVIDIA RTX 3090ï¼š

| æ•°æ®é›† | æ ·æœ¬æ•° | é¢„è®¡è€—æ—¶ | å­˜å‚¨ç©ºé—´ |
|--------|--------|---------|---------|
| MER2023 | 411 | ~5åˆ†é’Ÿ | ~500MB |
| MER2024 | 500 | ~6åˆ†é’Ÿ | ~600MB |
| CMU-MOSEI | ~2,500 | ~30åˆ†é’Ÿ | ~2.5GB |
| CMU-MOSI | ~2,200 | ~25åˆ†é’Ÿ | ~2.2GB |
| IEMOCAP | ~5,500 | ~60åˆ†é’Ÿ | ~5GB |
| MELD | ~2,600 | ~30åˆ†é’Ÿ | ~2.6GB |
| OVMERD+ | ~800 | ~10åˆ†é’Ÿ | ~800MB |
| SIMS | ~2,300 | ~25åˆ†é’Ÿ | ~2.3GB |
| SIMSv2 | ~2,300 | ~25åˆ†é’Ÿ | ~2.3GB |
| **æ€»è®¡** | **~19,000** | **~3.5å°æ—¶** | **~18GB** |

**æ³¨æ„**ï¼š
- æå–æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œä¹‹åæ¨ç†æ—¶å¯ä»¥æ— é™æ¬¡å¤ç”¨
- å¯ä»¥åå°è¿è¡Œæˆ–åˆ†æ‰¹å¤„ç†

---

## ğŸ” éªŒè¯ç‰¹å¾æ–‡ä»¶

```bash
# æ£€æŸ¥ç‰¹å¾æ–‡ä»¶æ•°é‡
ls preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/*.npy | wc -l

# æŸ¥çœ‹å•ä¸ªç‰¹å¾æ–‡ä»¶
python3 -c "
import numpy as np
feat = np.load('preextracted_features/mer2023/frame_CLIP_VIT_LARGE_emotion_peak_8frms/sample_00000001.npy')
print(f'Shape: {feat.shape}')  # åº”è¯¥æ˜¯ (8, 768)
print(f'Dtype: {feat.dtype}')  # åº”è¯¥æ˜¯ float32
print(f'Size: {feat.nbytes / 1024:.2f} KB')
"
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: MER-Factoryè¾“å‡ºä¸å­˜åœ¨æ€ä¹ˆåŠï¼Ÿ

**A**: éœ€è¦å…ˆè¿è¡ŒMER-Factoryç”Ÿæˆau_infoï¼š
```bash
cd /home/project/MER-Factory
python main.py --dataset mer2023 --modality video
```

### Q2: æŸäº›æ ·æœ¬æå–å¤±è´¥ï¼Ÿ

**A**: å¯èƒ½åŸå› ï¼š
- MER-Factoryæœªå¤„ç†è¯¥æ ·æœ¬ï¼ˆç¼ºå°‘au_infoï¼‰â†’ ä¼šè‡ªåŠ¨å›é€€åˆ°uniformé‡‡æ ·
- è§†é¢‘æ–‡ä»¶æŸåæˆ–è·¯å¾„é”™è¯¯ â†’ æ£€æŸ¥è§†é¢‘æ–‡ä»¶

### Q3: æ¨ç†æ—¶è¿˜æ˜¯å¾ˆæ…¢ï¼Ÿ

**A**: æ£€æŸ¥é…ç½®ï¼š
```yaml
# ç¡®ä¿è¿™ä¸‰é¡¹éƒ½é…ç½®æ­£ç¡®
use_preextracted_features: True  # â† å¿…é¡»æ˜¯True
preextracted_root: './preextracted_features/<dataset>'  # â† è·¯å¾„æ­£ç¡®
frame_sampling: 'emotion_peak'  # â† ä¸æå–æ—¶ä¸€è‡´
```

### Q4: èƒ½å¦æ··ç”¨uniformå’Œemotion_peak?

**A**: å¯ä»¥ï¼ä¸ºä¸åŒæ•°æ®é›†é…ç½®ä¸åŒçš„é‡‡æ ·ç­–ç•¥ï¼š
```yaml
datasets:
  mer2023:
    frame_sampling: 'emotion_peak'  # ä½¿ç”¨æ™ºèƒ½é‡‡æ ·
  mer2024:
    frame_sampling: 'uniform'       # ä½¿ç”¨å‡åŒ€é‡‡æ ·
```

### Q5: æå–è¿‡ç¨‹ä¸­æ–­äº†æ€ä¹ˆåŠï¼Ÿ

**A**: é‡æ–°è¿è¡Œè„šæœ¬ï¼Œä¼šè‡ªåŠ¨è·³è¿‡å·²æå–çš„æ ·æœ¬ï¼ˆæ£€æµ‹åˆ°.npyæ–‡ä»¶å­˜åœ¨ï¼‰ã€‚

---

## ğŸ“ æ€»ç»“

### âœ… ä¼˜ç‚¹
- **è¶…å¿«æ¨ç†**: æ¯”å®æ—¶emotion_peakå¿«600-1200å€
- **æ— éœ€au_info**: æ¨ç†æ—¶ä¸å†ä¾èµ–MER-Factoryè¾“å‡º
- **å¯å¤ç”¨**: ä¸€æ¬¡æå–ï¼Œæ— é™æ¬¡ä½¿ç”¨
- **ä¸è®­ç»ƒä¸€è‡´**: ä½¿ç”¨ç›¸åŒçš„emotion_peaké‡‡æ ·ç­–ç•¥

### âš ï¸ æ³¨æ„äº‹é¡¹
- **éœ€è¦MER-Factory**: æå–å‰å¿…é¡»å…ˆè¿è¡ŒMER-Factoryç”Ÿæˆau_info
- **å­˜å‚¨ç©ºé—´**: 9ä¸ªæ•°æ®é›†çº¦éœ€18GBç©ºé—´
- **ä¸€æ¬¡æ€§å¼€é”€**: é¦–æ¬¡æå–çº¦éœ€3.5å°æ—¶

### ğŸ’¡ å»ºè®®
- **æ¨ç†åœºæ™¯**: å¼ºçƒˆæ¨èé¢„æå–ï¼ˆå¿«é€Ÿä¸”ä¸€è‡´ï¼‰
- **å¼€å‘è°ƒè¯•**: å¯ä»¥å…ˆç”¨uniformé‡‡æ ·ï¼Œç¨³å®šåå†åˆ‡æ¢emotion_peak
- **ç”Ÿäº§ç¯å¢ƒ**: é¢„æå–æ˜¯æœ€ä½³å®è·µ

---

## ğŸ“§ ç›¸å…³æ–‡æ¡£

- `MY_README.md`: AffectGPTå®Œæ•´æ–‡æ¡£
- `video_processor.py`: emotion_peaké‡‡æ ·å®ç°
- `base_dataset.py`: é¢„æå–ç‰¹å¾åŠ è½½é€»è¾‘
