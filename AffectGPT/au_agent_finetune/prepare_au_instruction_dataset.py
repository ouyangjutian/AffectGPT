#!/usr/bin/env python3
"""
å‡†å¤‡AU Agentå¾®è°ƒæ•°æ®é›†
ä»MER-Factoryçš„AUåˆ†æç»“æœæ„å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®
"""

import json
import os
from pathlib import Path
from typing import List, Dict
import random
import pandas as pd
import ast


def load_label_mapping(csv_path: str) -> Dict[str, str]:
    """åŠ è½½æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„
    
    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„
    
    Returns:
        {video_name: emotion_labels} å­—å…¸
    """
    df = pd.read_csv(csv_path)
    label_map = {}
    
    for _, row in df.iterrows():
        video_name = row['name']
        openset = row['openset']
        
        # è§£æopensetï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼çš„åˆ—è¡¨ï¼‰
        if isinstance(openset, str):
            try:
                # å°è¯•è§£æä¸ºåˆ—è¡¨
                labels = ast.literal_eval(openset)
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
                labels = [openset]
        else:
            labels = [openset]
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾ä½œä¸ºä¸»è¦æƒ…æ„Ÿï¼Œæˆ–è€…æ‹¼æ¥æ‰€æœ‰æ ‡ç­¾
        # æ–¹æ¡ˆ1: åªç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾
        # emotion = labels[0] if labels else 'neutral'
        
        # æ–¹æ¡ˆ2: æ‹¼æ¥æ‰€æœ‰æ ‡ç­¾ï¼ˆæ›´ä¸°å¯Œï¼‰
        emotion = ', '.join(labels) if labels else 'neutral'
        
        label_map[video_name] = emotion
    
    return label_map


def load_au_analysis(json_path: str) -> Dict:
    """åŠ è½½AUåˆ†æJSON"""
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def create_instruction_sample(au_result: Dict, frame_idx: str, label_map: Dict[str, str] = None, video_name: str = None) -> Dict:
    """
    ä»AUåˆ†æç»“æœåˆ›å»ºæŒ‡ä»¤å¾®è°ƒæ ·æœ¬
    
    æ ¼å¼ï¼š
    {
        "instruction": "Based on the following Action Unit detections, describe the facial expression:",
        "input": "AU01: 0.98, AU05: 0.98, AU07: 2.35, AU25: 1.76",
        "output": "The facial expression exhibits subtle brow lowering, neutral ocular engagement with mild lid tightening, and slight lip parting, consistent with a prototypical neutral state."
    }
    """
    # è·å–fine-grainedæè¿°
    description = au_result.get('fine_grained_descriptions', {}).get(frame_idx, "")
    if not description:
        return None
    
    # ä»per_frame_au_descriptionsæ‰¾åˆ°å¯¹åº”å¸§çš„AUå€¼å’ŒAUæè¿°
    per_frame_data = au_result.get('per_frame_au_descriptions', [])
    au_values = None
    au_description = None
    
    # æŸ¥æ‰¾åŒ¹é…çš„å¸§
    frame_num = int(frame_idx)
    for frame_data in per_frame_data:
        if frame_data.get('frame') == frame_num:
            au_values = frame_data.get('active_aus', {})
            au_description = frame_data.get('au_description', None)  # æå–AUæè¿°
            break
    
    if not au_values:
        return None
    
    # æ„å»ºAUæ•°å€¼æ–‡æœ¬ï¼ˆç§»é™¤_råç¼€ï¼‰
    au_values_text = ", ".join([f"{au_id.replace('_r', '')}: {value:.2f}" for au_id, value in au_values.items()])
    
    # è·å–æƒ…æ„Ÿæ ‡ç­¾
    emotion_label = None
    if label_map and video_name:
        emotion_label = label_map.get(video_name, None)
    
    # Promptæ¨¡æ¿ï¼ˆè®ºæ–‡ä¸­çš„Tpï¼‰
    # æ¨èé€‰é¡¹: å¼ºè°ƒæƒ…æ„Ÿå¼•å¯¼å’Œå®Œæ•´è¾“å…¥ï¼ˆæ›´ç¬¦åˆè®ºæ–‡æ–¹æ³•ï¼‰
    prompt_tp = "Given the emotion label, AU intensity values, and their semantic descriptions, provide a detailed and natural facial expression description:"
    
    # å¤‡é€‰Promptæ¨¡æ¿ï¼ˆå¯ä»¥å–æ¶ˆæ³¨é‡Šä½¿ç”¨éšæœºé€‰æ‹©å¢å¼ºæ³›åŒ–ï¼‰:
    # prompt_templates = [
    #     "Given the emotion label, AU intensity values, and their semantic descriptions, provide a detailed and natural facial expression description:",
    #     "Describe the facial expression by analyzing the emotion context and Action Unit activations:",
    #     "Based on the provided emotion label and Action Unit data (including intensity values and semantic meanings), generate a comprehensive facial expression description:",
    #     "Describe the facial expression using the emotion label and AU detections provided:",
    # ]
    # prompt_tp = random.choice(prompt_templates)
    
    # æ ¹æ®æ˜¯å¦æœ‰æƒ…æ„Ÿæ ‡ç­¾æ„å»ºè¾“å…¥æ ¼å¼
    if emotion_label:
        # æœ‰æƒ…æ„Ÿæ ‡ç­¾ï¼šå®Œæ•´çš„è®ºæ–‡æ–¹æ³• = Label + Prompt (Tp) + AU values + AU descriptions
        # LLaMA-Factoryçš„instructionå­—æ®µç”¨äºä»»åŠ¡çº§åˆ«çš„æŒ‡ä»¤
        instruction = "Generate a detailed facial expression description based on the given information."
        
        # inputåŒ…å«ï¼šLabel + Prompt + AU values + AU descriptionsï¼ˆå®Œå…¨ç¬¦åˆè®ºæ–‡å›¾3aï¼‰
        if au_description:
            # æœ‰AUæè¿°ï¼šå®Œæ•´è¾“å…¥
            input_text = f"""Emotion: {emotion_label}
Prompt: {prompt_tp}
AU values: {au_values_text}
AU descriptions: {au_description}"""
        else:
            # æ— AUæè¿°ï¼šå›é€€åˆ°åªæœ‰AUå€¼
            input_text = f"""Emotion: {emotion_label}
Prompt: {prompt_tp}
AU detections: {au_values_text}"""
    else:
        # æ— æƒ…æ„Ÿæ ‡ç­¾ï¼šå›é€€åˆ° Prompt + AUs
        instruction = "Generate a facial expression description based on AU detections."
        if au_description:
            input_text = f"""Prompt: {prompt_tp}
AU values: {au_values_text}
AU descriptions: {au_description}"""
        else:
            input_text = f"""Prompt: {prompt_tp}
AU detections: {au_values_text}"""
    
    sample = {
        "instruction": instruction,
        "input": input_text,
        "output": description
    }
    
    return sample


def process_mer_factory_outputs(
    mer_factory_output_dir: str,
    output_json_path: str,
    label_csv_path: str = None,
    max_samples: int = None
):
    """
    å¤„ç†MER-Factoryè¾“å‡ºï¼Œæ„å»ºAUæŒ‡ä»¤æ•°æ®é›†
    
    Args:
        mer_factory_output_dir: MER-Factoryè¾“å‡ºç›®å½•
        output_json_path: è¾“å‡ºçš„æŒ‡ä»¤æ•°æ®é›†JSONè·¯å¾„
        label_csv_path: æƒ…æ„Ÿæ ‡ç­¾CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨Label+AUæ¨¡å¼ï¼‰
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆNone=å…¨éƒ¨ï¼‰
    """
    print("="*60)
    print("AU Instruction Dataset Preparation")
    print("="*60)
    
    # åŠ è½½æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„ï¼ˆå¦‚æœæä¾›ï¼‰
    label_map = None
    if label_csv_path and os.path.exists(label_csv_path):
        print(f"\nğŸ“‹ Loading emotion labels from: {label_csv_path}")
        label_map = load_label_mapping(label_csv_path)
        print(f"âœ… Loaded {len(label_map)} emotion labels")
    else:
        print(f"\nâš ï¸ No emotion label file provided, using AU-only mode")
    
    # æŸ¥æ‰¾æ‰€æœ‰AUåˆ†æJSON
    mer_factory_path = Path(mer_factory_output_dir)
    au_json_files = list(mer_factory_path.rglob('*_au_analysis.json'))
    
    print(f"\nğŸ“ Found {len(au_json_files)} AU analysis files")
    
    # æ”¶é›†æ‰€æœ‰æŒ‡ä»¤æ ·æœ¬
    all_samples = []
    
    for json_file in au_json_files:
        try:
            au_result = load_au_analysis(json_file)
            
            # æå–videoåç§°ï¼ˆä»æ–‡ä»¶è·¯å¾„æˆ–JSONä¸­çš„source_pathï¼‰
            video_name = json_file.stem.replace('_au_analysis', '')
            
            # ä¸ºæ¯ä¸€å¸§åˆ›å»ºæ ·æœ¬
            for frame_idx in au_result.get('fine_grained_descriptions', {}).keys():
                sample = create_instruction_sample(au_result, frame_idx, label_map, video_name)
                if sample:
                    all_samples.append(sample)
            
            if len(all_samples) % 1000 == 0:
                print(f"  Processed {len(all_samples)} samples...")
                
        except Exception as e:
            print(f"âš ï¸ Error processing {json_file}: {e}")
            continue
    
    print(f"\nâœ… Total samples collected: {len(all_samples)}")
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    if max_samples and len(all_samples) > max_samples:
        print(f"ğŸ“Š Sampling {max_samples} from {len(all_samples)} samples")
        all_samples = random.sample(all_samples, max_samples)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    random.shuffle(all_samples)
    split_idx = int(len(all_samples) * 0.95)
    train_samples = all_samples[:split_idx]
    val_samples = all_samples[split_idx:]
    
    print(f"ğŸ“Š Train: {len(train_samples)}, Val: {len(val_samples)}")
    
    # ä¿å­˜æ•°æ®é›†
    dataset = {
        "train": train_samples,
        "validation": val_samples,
        "metadata": {
            "total_samples": len(all_samples),
            "source": "MER-Factory AU Analysis",
            "format": "instruction_following",
            "description": "AU detection results to natural language descriptions"
        }
    }
    
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ Dataset saved to: {output_json_path}")
    
    # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
    print("\n" + "="*60)
    print("Sample Examples:")
    print("="*60)
    for i, sample in enumerate(train_samples[:3], 1):
        print(f"\n--- Example {i} ---")
        print(f"Instruction: {sample['instruction']}")
        print(f"Input: {sample['input']}")
        print(f"Output: {sample['output'][:150]}...")


def convert_to_llama_factory_format(
    instruction_dataset_path: str,
    output_train_jsonl: str,
    output_val_jsonl: str = None
):
    """
    è½¬æ¢ä¸ºLLaMA-Factoryæ ¼å¼
    
    æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªJSONï¼ŒåŒ…å«instructionã€inputã€output
    """
    with open(instruction_dataset_path, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    train_samples = dataset['train']
    val_samples = dataset.get('validation', [])
    
    # ä¿å­˜è®­ç»ƒé›†JSONL
    with open(output_train_jsonl, 'w', encoding='utf-8') as f:
        for sample in train_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    print(f"âœ… Train JSONL saved to: {output_train_jsonl}")
    
    # ä¿å­˜éªŒè¯é›†JSONLï¼ˆå¦‚æœæœ‰ï¼‰
    if output_val_jsonl and val_samples:
        with open(output_val_jsonl, 'w', encoding='utf-8') as f:
            for sample in val_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        print(f"âœ… Val JSONL saved to: {output_val_jsonl}")
    
    return len(train_samples), len(val_samples)


if __name__ == '__main__':
    # é…ç½®
    MER_FACTORY_OUTPUT = '/home/project/MER-Factory/output'
    LABEL_CSV_PATH = '/home/project/Dataset/Emotion/MER2025/dataset/mer2025-dataset/track2_train_mercaptionplus_test.csv'  # æƒ…æ„Ÿæ ‡ç­¾CSV
    OUTPUT_JSON = './au_instruction_dataset.json'  # ä¿å­˜åœ¨au_agent_finetuneæ–‡ä»¶å¤¹
    OUTPUT_TRAIN_JSONL = './au_instruction_dataset_train.jsonl'  # è®­ç»ƒé›†
    OUTPUT_VAL_JSONL = './au_instruction_dataset_val.jsonl'      # éªŒè¯é›†
    
    # å‡†å¤‡æ•°æ®é›†
    process_mer_factory_outputs(
        mer_factory_output_dir=MER_FACTORY_OUTPUT,
        label_csv_path=LABEL_CSV_PATH,
        output_json_path=OUTPUT_JSON,
        max_samples=100000  # é™åˆ¶10ä¸‡æ ·æœ¬
    )
    
    # è½¬æ¢ä¸ºLLaMA-Factoryæ ¼å¼ï¼ˆç”Ÿæˆtrainå’Œvalä¸¤ä¸ªæ–‡ä»¶ï¼‰
    train_count, val_count = convert_to_llama_factory_format(
        OUTPUT_JSON, 
        OUTPUT_TRAIN_JSONL,
        OUTPUT_VAL_JSONL
    )
    
    print("\n" + "="*60)
    print("Dataset preparation complete!")
    print("="*60)
    print(f"\nğŸ“Š Dataset Statistics:")
    print(f"  - Train samples: {train_count}")
    print(f"  - Val samples: {val_count}")
    print(f"\nğŸ“ Generated Files:")
    print(f"  - Full dataset: {OUTPUT_JSON}")
    print(f"  - Train JSONL: {OUTPUT_TRAIN_JSONL}")
    print(f"  - Val JSONL: {OUTPUT_VAL_JSONL}")
    print(f"\nğŸš€ Next steps:")
    print(f"1. Review dataset quality")
    print(f"2. Run training: bash train_au_agent.sh")
    print(f"3. Test AU Agent generation quality")
